{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice Formatting within Jupyter Notebook\n",
    "%matplotlib inline\n",
    "#from IPython.display import display # Allows multiple displays from a single code-cell\n",
    "\n",
    "# System functionality\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import Here any Additional modules you use. To import utilities we provide, use something like:\n",
    "#   from utils.plotter import plot_hinton\n",
    "\n",
    "# Your Code goes here:\n",
    "#from __future__ import division, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split #, KFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn import preprocessing\n",
    "from numpy import unravel_index\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy import linspace\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column noames to filter for experiments\n",
    "\n",
    "LAI = ['LAI_0322', 'LAI_0421', 'LAI_0513', 'LAI_0617', \n",
    "       'LAI_0702', 'LAI_0720', 'LAI_0809', 'LAI_0821', 'LAI_0920']\n",
    "\n",
    "S2 = ['B02_0322', 'B03_0322', 'B04_0322', 'B05_0322',\n",
    "       'B06_0322', 'B07_0322', 'B08A_0322', 'B08_0322', 'B11_0322', 'B12_0322',\n",
    "       'B02_0421', 'B03_0421', 'B04_0421', 'B05_0421', 'B06_0421',\n",
    "       'B07_0421', 'B08A_0421', 'B08_0421', 'B11_0421', 'B12_0421',\n",
    "       'B02_0513', 'B03_0513', 'B04_0513', 'B05_0513', 'B06_0513', 'B07_0513',\n",
    "       'B08A_0513', 'B08_0513', 'B11_0513', 'B12_0513', 'B02_0617',\n",
    "       'B03_0617', 'B04_0617', 'B05_0617', 'B06_0617', 'B07_0617', 'B08A_0617',\n",
    "       'B08_0617', 'B11_0617', 'B12_0617', 'B02_0702', 'B03_0702',\n",
    "       'B04_0702', 'B05_0702', 'B06_0702', 'B07_0702', 'B08A_0702', 'B08_0702',\n",
    "       'B11_0702', 'B12_0702', 'B02_0720', 'B03_0720', 'B04_0720',\n",
    "       'B05_0720', 'B06_0720', 'B07_0720', 'B08A_0720', 'B08_0720', 'B11_0720',\n",
    "       'B12_0720', 'B02_0809', 'B03_0809', 'B04_0809', 'B05_0809',\n",
    "       'B06_0809', 'B07_0809', 'B08A_0809', 'B08_0809', 'B11_0809', 'B12_0809',\n",
    "       'B02_0821', 'B03_0821', 'B04_0821', 'B05_0821', 'B06_0821',\n",
    "       'B07_0821', 'B08A.jp_0821', 'B08_0821', 'B11_0821', 'B12_0821',\n",
    "       'B02_0920', 'B03_0920', 'B04_0920', 'B05_0920', 'B06_0920',\n",
    "       'B07_0920', 'B08A_0920', 'B08_0920', 'B11_0920', 'B12_0920']\n",
    "\n",
    "S1 = ['VH_20180303', 'VV_20180303', 'VH_20180311', 'VV_20180311',\n",
    "       'VH_20180315', 'VV_20180315', 'VH_20180323', 'VV_20180323',\n",
    "       'VH_20180327', 'VV_20180327', 'VH_20180404', 'VV_20180404',\n",
    "       'VH_20180408', 'VV_20180408', 'VH_20180416', 'VV_20180416',\n",
    "       'VH_20180420', 'VV_20180420', 'VH_20180428', 'VV_20180428',\n",
    "       'VH_20180502', 'VV_20180502', 'VH_20180510', 'VV_20180510',\n",
    "       'VH_20180522', 'VV_20180522', 'VH_20180526', 'VV_20180526',\n",
    "       'VH_20180603', 'VV_20180603', 'VH_20180607', 'VV_20180607',\n",
    "       'VH_20180615', 'VV_20180615', 'VH_20180619', 'VV_20180619',\n",
    "       'VH_20180627', 'VV_20180627', 'VH_20180701', 'VV_20180701',\n",
    "       'VH_20180709', 'VV_20180709', 'VH_20180713', 'VV_20180713',\n",
    "       'VH_20180721', 'VV_20180721', 'VH_20180725', 'VV_20180725',\n",
    "       'VH_20180802', 'VV_20180802', 'VH_20180806', 'VV_20180806',\n",
    "       'VH_20180814', 'VV_20180814', 'VH_20180818', 'VV_20180818',\n",
    "       'VH_20180826', 'VV_20180826', 'VH_20180830', 'VV_20180830',\n",
    "       'VH_20180907', 'VV_20180907', 'VH_20180911', 'VV_20180911',\n",
    "       'VH_20180919', 'VV_20180919', 'VH_20180923', 'VV_20180923',\n",
    "       'VH_20180305', 'VV_20180305', 'VH_20180309', 'VV_20180309',\n",
    "       'VH_20180317', 'VV_20180317', 'VH_20180321', 'VV_20180321',\n",
    "       'VH_20180329', 'VV_20180329', 'VH_20180402', 'VV_20180402',\n",
    "       'VH_20180410', 'VV_20180410', 'VH_20180414', 'VV_20180414',\n",
    "       'VH_20180422', 'VV_20180422', 'VH_20180426', 'VV_20180426',\n",
    "       'VH_20180504', 'VV_20180504', 'VH_20180508', 'VV_20180508',\n",
    "       'VH_20180516', 'VV_20180516', 'VH_20180520', 'VV_20180520',\n",
    "       'VH_20180528', 'VV_20180528', 'VH_20180601', 'VV_20180601', \n",
    "       'VH_20180609', 'VV_20180609', 'VH_20180613', 'VV_20180613', \n",
    "       'VH_20180621', 'VV_20180621', 'VH_20180625',\n",
    "       'VV_20180625', 'VH_20180703', 'VV_20180703', 'VH_20180707',\n",
    "       'VV_20180707', 'VH_20180715', 'VV_20180715', 'VH_20180719',\n",
    "       'VV_20180719', 'VH_20180727', 'VV_20180727', 'VH_20180731',\n",
    "       'VV_20180731', 'VH_20180808', 'VV_20180808', 'VH_20180812',\n",
    "       'VV_20180812', 'VH_20180820', 'VV_20180820', 'VH_20180824',\n",
    "       'VV_20180824', 'VH_20180901', 'VV_20180901', 'VH_20180905',\n",
    "       'VV_20180905', 'VH_20180913', 'VV_20180913', 'VH_20180917',\n",
    "       'VV_20180917', 'VH_20180925', 'VV_20180925', 'VH_20180929',\n",
    "       'VV_20180929'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "###   load data   ###\n",
    "#####################\n",
    "\n",
    "# load datasets\n",
    "data_path = \"/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s1_s2_raster/data/train_data_org.csv\"\n",
    "train_org = pd.read_csv(data_path, delimiter = ',', index_col=0)\n",
    "data_path = \"/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s1_s2_raster/data/test_data.csv\"\n",
    "test_org = pd.read_csv(data_path, delimiter = ',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: number of instances: 1200, number of attributes: 11\n",
      "Test: number of instances: 4584, number of attributes: 11\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "###   preprocess data   ###\n",
    "###########################\n",
    "\n",
    "experiment = LAI\n",
    "\n",
    "# filter for experiments\n",
    "train = train_org[['crop_id', 'geometry'] + experiment]\n",
    "test = test_org[['crop_id', 'geometry'] + experiment]\n",
    "\n",
    "train = shuffle(train, random_state=399)\n",
    "\n",
    "X_train = train.drop(['crop_id','geometry'], axis=1).values\n",
    "y_train = train['crop_id'].values\n",
    "X_test = test.drop(['crop_id','geometry'], axis=1).values\n",
    "y_test = test['crop_id'].values\n",
    "\n",
    "print(\"Train: number of instances: {}, number of attributes: {}\".format(train.shape[0], train.shape[1]))\n",
    "print(\"Test: number of instances: {}, number of attributes: {}\".format(test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crop_id                                     geometry  LAI_0322  \\\n",
      "id                                                                     \n",
      "168         2  POINT (634740.5100236891 5339978.909767563)        36   \n",
      "669        10   POINT (624908.0456842275 5335769.90775792)       -31   \n",
      "1157       15  POINT (621332.3669208327 5360109.999892802)       108   \n",
      "264         6  POINT (639971.0221898934 5343010.385524059)       109   \n",
      "194         2   POINT (639366.526787769 5338334.476987346)       -46   \n",
      "679        10  POINT (620109.7202541821 5354703.312341657)       -74   \n",
      "327         3  POINT (632185.2000834884 5348559.848026753)       581   \n",
      "\n",
      "      LAI_0421  LAI_0513  LAI_0617  LAI_0702  LAI_0720  LAI_0809  LAI_0821  \\\n",
      "id                                                                           \n",
      "168        124       212      1571      2456      1677      3656      2750   \n",
      "669        240       240      1405      3185      1626       349       360   \n",
      "1157       263       422       501       357      1585       224       211   \n",
      "264         93       380      3610      4300      1607       742       764   \n",
      "194        128       251      2856      3513       899      3876      2744   \n",
      "679        137       212       367      1532      1636       862       470   \n",
      "327       2226      1475       339       444      1604       359       354   \n",
      "\n",
      "      LAI_0920  \n",
      "id              \n",
      "168       1229  \n",
      "669        117  \n",
      "1157       153  \n",
      "264       -175  \n",
      "194       1077  \n",
      "679        305  \n",
      "327        231  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crop_id</th>\n",
       "      <th>LAI_0322</th>\n",
       "      <th>LAI_0421</th>\n",
       "      <th>LAI_0513</th>\n",
       "      <th>LAI_0617</th>\n",
       "      <th>LAI_0702</th>\n",
       "      <th>LAI_0720</th>\n",
       "      <th>LAI_0809</th>\n",
       "      <th>LAI_0821</th>\n",
       "      <th>LAI_0920</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "      <td>1200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.500000</td>\n",
       "      <td>194.252500</td>\n",
       "      <td>792.165833</td>\n",
       "      <td>863.820833</td>\n",
       "      <td>1640.691667</td>\n",
       "      <td>1926.732500</td>\n",
       "      <td>1436.435833</td>\n",
       "      <td>1051.773333</td>\n",
       "      <td>677.485833</td>\n",
       "      <td>535.388333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.892506</td>\n",
       "      <td>324.810193</td>\n",
       "      <td>1151.337292</td>\n",
       "      <td>1085.610580</td>\n",
       "      <td>1485.749772</td>\n",
       "      <td>1744.913608</td>\n",
       "      <td>988.565723</td>\n",
       "      <td>1127.079973</td>\n",
       "      <td>785.011867</td>\n",
       "      <td>751.849365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-202.000000</td>\n",
       "      <td>-44.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>169.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>-189.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.500000</td>\n",
       "      <td>-26.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>262.000000</td>\n",
       "      <td>460.000000</td>\n",
       "      <td>404.000000</td>\n",
       "      <td>797.000000</td>\n",
       "      <td>267.000000</td>\n",
       "      <td>234.000000</td>\n",
       "      <td>102.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>76.500000</td>\n",
       "      <td>243.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>1094.500000</td>\n",
       "      <td>1328.500000</td>\n",
       "      <td>1598.000000</td>\n",
       "      <td>559.500000</td>\n",
       "      <td>375.000000</td>\n",
       "      <td>241.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.250000</td>\n",
       "      <td>316.000000</td>\n",
       "      <td>892.500000</td>\n",
       "      <td>842.250000</td>\n",
       "      <td>2458.000000</td>\n",
       "      <td>3088.000000</td>\n",
       "      <td>1622.250000</td>\n",
       "      <td>1346.750000</td>\n",
       "      <td>718.500000</td>\n",
       "      <td>686.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16.000000</td>\n",
       "      <td>1979.000000</td>\n",
       "      <td>6119.000000</td>\n",
       "      <td>6035.000000</td>\n",
       "      <td>13060.000000</td>\n",
       "      <td>9892.000000</td>\n",
       "      <td>11370.000000</td>\n",
       "      <td>6044.000000</td>\n",
       "      <td>4904.000000</td>\n",
       "      <td>6155.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           crop_id     LAI_0322     LAI_0421     LAI_0513      LAI_0617  \\\n",
       "count  1200.000000  1200.000000  1200.000000  1200.000000   1200.000000   \n",
       "mean      8.500000   194.252500   792.165833   863.820833   1640.691667   \n",
       "std       4.892506   324.810193  1151.337292  1085.610580   1485.749772   \n",
       "min       1.000000  -202.000000   -44.000000    90.000000    137.000000   \n",
       "25%       4.500000   -26.000000   178.000000   262.000000    460.000000   \n",
       "50%       9.000000    76.500000   243.000000   329.000000   1094.500000   \n",
       "75%      12.250000   316.000000   892.500000   842.250000   2458.000000   \n",
       "max      16.000000  1979.000000  6119.000000  6035.000000  13060.000000   \n",
       "\n",
       "          LAI_0702      LAI_0720     LAI_0809     LAI_0821     LAI_0920  \n",
       "count  1200.000000   1200.000000  1200.000000  1200.000000  1200.000000  \n",
       "mean   1926.732500   1436.435833  1051.773333   677.485833   535.388333  \n",
       "std    1744.913608    988.565723  1127.079973   785.011867   751.849365  \n",
       "min      62.000000    169.000000    11.000000   -35.000000  -189.000000  \n",
       "25%     404.000000    797.000000   267.000000   234.000000   102.750000  \n",
       "50%    1328.500000   1598.000000   559.500000   375.000000   241.000000  \n",
       "75%    3088.000000   1622.250000  1346.750000   718.500000   686.250000  \n",
       "max    9892.000000  11370.000000  6044.000000  4904.000000  6155.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##########################\n",
    "###   exploring data   ###\n",
    "##########################\n",
    "\n",
    "print(train.head(7))\n",
    "\n",
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "###   standardize data   ###\n",
    "############################\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "##########################\n",
    "###                    ###\n",
    "###   Classification   ###\n",
    "###                    ###\n",
    "##########################\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "###   RFC - Random Forest Classifier   ###\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666667 [0.58333333 0.65833333 0.63333333 0.68333333 0.69166667 0.65833333\n",
      " 0.63333333 0.69166667 0.71666667 0.71666667]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=399, n_jobs=8)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "print(np.mean(scores), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9662308509909756 [0.97033013 0.96698705 0.96155453 0.9653155  0.96030088 0.96573339\n",
      " 0.96782282 0.96906355 0.96948161 0.96571906]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=10, max_depth=None, min_samples_split=2, random_state=399, n_jobs=8)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "print(np.mean(scores), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [1, 10, 100, 1000], 'criterion': ['gini', 'entropy'], \\\n",
    "     'max_depth': [None, 10, 100, 1000], 'max_features': ['sqrt', 'log2', None], },\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=8,\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'max_depth': [None, 10, 100, 1000],\n",
       "                          'max_features': ['sqrt', 'log2', None],\n",
       "                          'n_estimators': [1, 10, 100, 1000]}])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, n_jobs=8)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best parameters set found on development set:  {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "\n",
      "Best mean cross-validated score: 0.7033333333333334\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Grid scores for SVM:\n",
      "\n",
      "0.551 (+/-0.066) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.657 (+/-0.055) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.693 (+/-0.081) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.696 (+/-0.079) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.523 (+/-0.079) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.662 (+/-0.076) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.702 (+/-0.066) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.696 (+/-0.084) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.573 (+/-0.059) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 1}\n",
      "0.659 (+/-0.099) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 10}\n",
      "0.681 (+/-0.067) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 100}\n",
      "0.687 (+/-0.069) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 1000}\n",
      "0.546 (+/-0.049) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.671 (+/-0.061) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.689 (+/-0.075) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.686 (+/-0.072) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.518 (+/-0.106) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.663 (+/-0.057) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.697 (+/-0.060) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.694 (+/-0.074) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.559 (+/-0.079) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 1}\n",
      "0.654 (+/-0.066) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 10}\n",
      "0.681 (+/-0.070) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 100}\n",
      "0.680 (+/-0.078) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 1000}\n",
      "0.528 (+/-0.071) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.663 (+/-0.070) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.695 (+/-0.072) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.693 (+/-0.069) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.533 (+/-0.072) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.666 (+/-0.070) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.689 (+/-0.085) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.693 (+/-0.080) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.540 (+/-0.058) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 1}\n",
      "0.660 (+/-0.066) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 10}\n",
      "0.680 (+/-0.059) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 100}\n",
      "0.692 (+/-0.087) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 1000}\n",
      "0.523 (+/-0.097) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.660 (+/-0.061) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.693 (+/-0.072) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.697 (+/-0.084) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.534 (+/-0.088) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.663 (+/-0.074) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.681 (+/-0.072) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.694 (+/-0.072) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.569 (+/-0.073) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1}\n",
      "0.653 (+/-0.086) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 10}\n",
      "0.680 (+/-0.075) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 100}\n",
      "0.688 (+/-0.076) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1000}\n",
      "0.533 (+/-0.089) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.656 (+/-0.093) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.701 (+/-0.069) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.698 (+/-0.077) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.549 (+/-0.093) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.665 (+/-0.077) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.697 (+/-0.068) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.700 (+/-0.077) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.561 (+/-0.085) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 1}\n",
      "0.653 (+/-0.061) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 10}\n",
      "0.692 (+/-0.071) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 100}\n",
      "0.694 (+/-0.067) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 1000}\n",
      "0.541 (+/-0.103) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.667 (+/-0.061) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.690 (+/-0.075) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.697 (+/-0.061) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.525 (+/-0.078) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.648 (+/-0.086) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.692 (+/-0.079) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.698 (+/-0.073) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.562 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 1}\n",
      "0.657 (+/-0.095) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 10}\n",
      "0.690 (+/-0.076) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 100}\n",
      "0.693 (+/-0.076) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 1000}\n",
      "0.554 (+/-0.081) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.662 (+/-0.082) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.699 (+/-0.066) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.697 (+/-0.085) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.537 (+/-0.049) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.672 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.698 (+/-0.097) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.700 (+/-0.075) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.556 (+/-0.120) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 1}\n",
      "0.657 (+/-0.102) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 10}\n",
      "0.688 (+/-0.065) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 100}\n",
      "0.689 (+/-0.070) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 1000}\n",
      "0.570 (+/-0.076) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.657 (+/-0.102) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.695 (+/-0.093) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.703 (+/-0.064) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.539 (+/-0.073) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.662 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.688 (+/-0.092) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.703 (+/-0.079) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.555 (+/-0.054) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1}\n",
      "0.637 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 10}\n",
      "0.687 (+/-0.081) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 100}\n",
      "0.692 (+/-0.065) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1000}\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Best parameters set found on development set: \", clf.best_params_)\n",
    "print()\n",
    "print('Best mean cross-validated score:', clf.best_score_)\n",
    "print()\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Grid scores for SVM:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print(\"------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [600,1000,3000], 'criterion': ['gini'], \\\n",
    "     'max_depth': [1000], 'max_features': ['sqrt'], },\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c52ee6f42ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/kaggle/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, n_jobs=8)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best parameters set found on development set:  {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 600}\n",
      "\n",
      "Best mean cross-validated score: 0.8358333333333332\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Grid scores for SVM:\n",
      "\n",
      "0.836 (+/-0.045) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 600}\n",
      "0.833 (+/-0.061) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.835 (+/-0.062) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 3000}\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Best parameters set found on development set: \", clf.best_params_)\n",
    "print()\n",
    "print('Best mean cross-validated score:', clf.best_score_)\n",
    "print()\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Grid scores for SVM:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print(\"------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "###   SVC - Support Vector Classifier   ###\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6483333333333332 [0.65833333 0.61666667 0.6        0.625      0.71666667 0.68333333\n",
      " 0.675      0.65       0.64166667 0.61666667]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear', C=1, random_state=399)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, n_jobs=8)\n",
    "print(np.mean(scores), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'], 'kernel': ['rbf']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'], 'degree': [2, 3, 4], 'kernel': ['poly']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'], 'kernel': ['sigmoid']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=8,\n",
       "             param_grid=[{'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
       "                         {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'],\n",
       "                          'kernel': ['rbf']},\n",
       "                         {'C': [1, 10, 100, 1000], 'degree': [2, 3, 4],\n",
       "                          'gamma': ['scale', 'auto'], 'kernel': ['poly']},\n",
       "                         {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'],\n",
       "                          'kernel': ['sigmoid']}])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVC(), param_grid, cv=10, n_jobs=8)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best parameters set found on development set:  {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "\n",
      "Best mean cross-validated score: 0.6883333333333334\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Grid scores for SVM:\n",
      "\n",
      "0.648 (+/-0.068) for {'C': 1, 'kernel': 'linear'}\n",
      "0.657 (+/-0.074) for {'C': 10, 'kernel': 'linear'}\n",
      "0.660 (+/-0.081) for {'C': 100, 'kernel': 'linear'}\n",
      "0.651 (+/-0.083) for {'C': 1000, 'kernel': 'linear'}\n",
      "0.636 (+/-0.066) for {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.637 (+/-0.069) for {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.687 (+/-0.065) for {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.688 (+/-0.063) for {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.664 (+/-0.083) for {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.663 (+/-0.082) for {'C': 100, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.650 (+/-0.076) for {'C': 1000, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.648 (+/-0.078) for {'C': 1000, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "0.589 (+/-0.041) for {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.588 (+/-0.037) for {'C': 1, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.536 (+/-0.061) for {'C': 1, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.534 (+/-0.061) for {'C': 1, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.432 (+/-0.060) for {'C': 1, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.432 (+/-0.058) for {'C': 1, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.641 (+/-0.070) for {'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.640 (+/-0.071) for {'C': 10, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.637 (+/-0.068) for {'C': 10, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.637 (+/-0.068) for {'C': 10, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.557 (+/-0.072) for {'C': 10, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.555 (+/-0.067) for {'C': 10, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.660 (+/-0.067) for {'C': 100, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.658 (+/-0.069) for {'C': 100, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.661 (+/-0.049) for {'C': 100, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.662 (+/-0.050) for {'C': 100, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.619 (+/-0.036) for {'C': 100, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.621 (+/-0.039) for {'C': 100, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.640 (+/-0.095) for {'C': 1000, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.640 (+/-0.094) for {'C': 1000, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.654 (+/-0.085) for {'C': 1000, 'degree': 3, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.655 (+/-0.082) for {'C': 1000, 'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.602 (+/-0.059) for {'C': 1000, 'degree': 4, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.600 (+/-0.061) for {'C': 1000, 'degree': 4, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "0.448 (+/-0.056) for {'C': 1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.448 (+/-0.054) for {'C': 1, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.413 (+/-0.068) for {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.415 (+/-0.063) for {'C': 10, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.404 (+/-0.065) for {'C': 100, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.407 (+/-0.067) for {'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid'}\n",
      "0.397 (+/-0.067) for {'C': 1000, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.390 (+/-0.077) for {'C': 1000, 'gamma': 'auto', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Best parameters set found on development set: \", clf.best_params_)\n",
    "print()\n",
    "print('Best mean cross-validated score:', clf.best_score_)\n",
    "print()\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Grid scores for SVM:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###   Prediction   ###\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction with the best preforming model\n",
    "clf = SVC(kernel='rbf', C=10, gamma='scale', random_state=399)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[369,   1,   1,  18,   2,   1,   4,   1,   0,   1,   1,   1],\n",
       "       [  2, 381,   0,  15,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 391,   6,   0,   0,   0,   0,   0,   0,   2,   1],\n",
       "       [  5,   6,   6, 336,   9,   0,   2,   0,   2,   8,  20,   6],\n",
       "       [  2,  14,   0,   8, 335,   3,   7,  16,   0,   0,  15,   0],\n",
       "       [  2,   7,   0,  18,   3, 364,   2,   2,   0,   0,   0,   2],\n",
       "       [  0,   0,   0,   6,   3,   3, 382,   4,   0,   0,   0,   2],\n",
       "       [  1,   1,   0,   4,  14,   3,   8, 367,   0,   0,   2,   0],\n",
       "       [  0,   0,   0,   2,   0,   0,   0,   0, 388,   0,  10,   0],\n",
       "       [  0,   0,   1,   4,   0,   0,   0,   3,   0, 387,   3,   2],\n",
       "       [  3,   0,   0,   1,   3,   0,   0,   0,   0,   3, 370,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 204]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9323734729493892"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction with the best preforming model\n",
    "clf = SVC(kernel='rbf', C=10, gamma='scale', random_state=399)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[376,   0,   2,  10,   1,   6,   2,   2,   0,   0,   0,   1],\n",
       "       [  4, 389,   0,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 396,   2,   0,   0,   0,   0,   0,   1,   1,   0],\n",
       "       [  6,   7,   6, 345,   7,   0,   1,   1,   2,   6,  16,   3],\n",
       "       [  0,  11,   0,   5, 355,   1,   9,   5,   0,   0,  14,   0],\n",
       "       [  5,   2,   0,   9,   2, 381,   0,   0,   0,   0,   0,   1],\n",
       "       [  1,   0,   0,   2,   1,   4, 392,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   1,   7,   0,   1, 389,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 396,   0,   4,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   2,   0, 394,   3,   1],\n",
       "       [  3,   0,   0,   1,   4,   0,   0,   0,   0,   0, 372,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 204]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574607329842932"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tabnet\n",
      "  Using cached pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
      "Processing /home/philipp/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0/wget-3.2-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /home/philipp/.local/lib/python3.8/site-packages (from pytorch-tabnet) (4.61.0)\n",
      "Requirement already satisfied: scipy>1.4 in /home/philipp/.local/lib/python3.8/site-packages (from pytorch-tabnet) (1.7.0)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /home/philipp/.local/lib/python3.8/site-packages (from pytorch-tabnet) (0.24.2)\n",
      "Collecting torch<2.0,>=1.2\n",
      "  Using cached torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/lib/python3/dist-packages (from pytorch-tabnet) (1.17.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/philipp/.local/lib/python3.8/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/philipp/.local/lib/python3.8/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/philipp/.local/lib/python3.8/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.10.0.0)\n",
      "Installing collected packages: torch, pytorch-tabnet, wget\n",
      "Successfully installed pytorch-tabnet-3.1.1 torch-1.9.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-tabnet wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = round(X_train.shape[0]*0.9)\n",
    "\n",
    "X_trainx = X_train[:l]\n",
    "y_trainx = y_train[:l]\n",
    "\n",
    "X_validx = X_train[l:]\n",
    "y_validx = y_train[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "# network parameters\n",
    "clf = TabNetClassifier(\n",
    "    n_d=16, n_a=16, n_steps=5,\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "    #cat_idxs=cat_idxs,\n",
    "    #cat_dims=cat_dims,\n",
    "    cat_emb_dim=1,\n",
    "    lambda_sparse=1e-2, momentum=0.3, #clip_value=2.,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params = {\"gamma\": 0.95,\n",
    "                     \"step_size\": 20},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.20292 | train_accuracy: 0.95391 | valid_accuracy: 0.8918  |  0:00:00s\n",
      "epoch 1  | loss: 0.17289 | train_accuracy: 0.95437 | valid_accuracy: 0.90271 |  0:00:01s\n",
      "epoch 2  | loss: 0.15513 | train_accuracy: 0.96895 | valid_accuracy: 0.90729 |  0:00:02s\n",
      "epoch 3  | loss: 0.12155 | train_accuracy: 0.9682  | valid_accuracy: 0.90969 |  0:00:02s\n",
      "epoch 4  | loss: 0.11428 | train_accuracy: 0.97263 | valid_accuracy: 0.90794 |  0:00:03s\n",
      "epoch 5  | loss: 0.09591 | train_accuracy: 0.97526 | valid_accuracy: 0.91558 |  0:00:04s\n",
      "epoch 6  | loss: 0.08564 | train_accuracy: 0.97823 | valid_accuracy: 0.92081 |  0:00:04s\n",
      "epoch 7  | loss: 0.08166 | train_accuracy: 0.98178 | valid_accuracy: 0.92277 |  0:00:05s\n",
      "epoch 8  | loss: 0.07454 | train_accuracy: 0.98362 | valid_accuracy: 0.92168 |  0:00:06s\n",
      "epoch 9  | loss: 0.06978 | train_accuracy: 0.98458 | valid_accuracy: 0.92343 |  0:00:06s\n",
      "epoch 10 | loss: 0.06363 | train_accuracy: 0.98349 | valid_accuracy: 0.92408 |  0:00:07s\n",
      "epoch 11 | loss: 0.06306 | train_accuracy: 0.98471 | valid_accuracy: 0.9243  |  0:00:08s\n",
      "epoch 12 | loss: 0.06098 | train_accuracy: 0.98588 | valid_accuracy: 0.92627 |  0:00:08s\n",
      "epoch 13 | loss: 0.05864 | train_accuracy: 0.98788 | valid_accuracy: 0.92866 |  0:00:09s\n",
      "epoch 14 | loss: 0.05438 | train_accuracy: 0.98926 | valid_accuracy: 0.92976 |  0:00:10s\n",
      "epoch 15 | loss: 0.0514  | train_accuracy: 0.98997 | valid_accuracy: 0.93106 |  0:00:11s\n",
      "epoch 16 | loss: 0.04667 | train_accuracy: 0.99043 | valid_accuracy: 0.92976 |  0:00:11s\n",
      "epoch 17 | loss: 0.046   | train_accuracy: 0.99139 | valid_accuracy: 0.93019 |  0:00:12s\n",
      "epoch 18 | loss: 0.04363 | train_accuracy: 0.99202 | valid_accuracy: 0.92997 |  0:00:13s\n",
      "epoch 19 | loss: 0.04048 | train_accuracy: 0.99277 | valid_accuracy: 0.92779 |  0:00:13s\n",
      "epoch 20 | loss: 0.03824 | train_accuracy: 0.99265 | valid_accuracy: 0.92888 |  0:00:14s\n",
      "epoch 21 | loss: 0.03774 | train_accuracy: 0.99369 | valid_accuracy: 0.92954 |  0:00:15s\n",
      "epoch 22 | loss: 0.03592 | train_accuracy: 0.99419 | valid_accuracy: 0.92976 |  0:00:16s\n",
      "epoch 23 | loss: 0.03296 | train_accuracy: 0.99415 | valid_accuracy: 0.93128 |  0:00:16s\n",
      "epoch 24 | loss: 0.03307 | train_accuracy: 0.99444 | valid_accuracy: 0.93106 |  0:00:17s\n",
      "epoch 25 | loss: 0.03167 | train_accuracy: 0.99519 | valid_accuracy: 0.93019 |  0:00:18s\n",
      "epoch 26 | loss: 0.0293  | train_accuracy: 0.99486 | valid_accuracy: 0.93063 |  0:00:18s\n",
      "epoch 27 | loss: 0.02971 | train_accuracy: 0.99549 | valid_accuracy: 0.92801 |  0:00:19s\n",
      "epoch 28 | loss: 0.02849 | train_accuracy: 0.99607 | valid_accuracy: 0.9315  |  0:00:20s\n",
      "epoch 29 | loss: 0.02673 | train_accuracy: 0.99536 | valid_accuracy: 0.9315  |  0:00:20s\n",
      "epoch 30 | loss: 0.02512 | train_accuracy: 0.99611 | valid_accuracy: 0.93368 |  0:00:21s\n",
      "epoch 31 | loss: 0.02464 | train_accuracy: 0.99616 | valid_accuracy: 0.93041 |  0:00:22s\n",
      "epoch 32 | loss: 0.02302 | train_accuracy: 0.99649 | valid_accuracy: 0.93106 |  0:00:22s\n",
      "epoch 33 | loss: 0.02439 | train_accuracy: 0.99707 | valid_accuracy: 0.9315  |  0:00:23s\n",
      "epoch 34 | loss: 0.02249 | train_accuracy: 0.99678 | valid_accuracy: 0.93412 |  0:00:24s\n",
      "epoch 35 | loss: 0.02165 | train_accuracy: 0.99695 | valid_accuracy: 0.93412 |  0:00:24s\n",
      "epoch 36 | loss: 0.02077 | train_accuracy: 0.9972  | valid_accuracy: 0.9363  |  0:00:25s\n",
      "epoch 37 | loss: 0.02148 | train_accuracy: 0.99762 | valid_accuracy: 0.93346 |  0:00:26s\n",
      "epoch 38 | loss: 0.0205  | train_accuracy: 0.99749 | valid_accuracy: 0.93303 |  0:00:26s\n",
      "epoch 39 | loss: 0.01893 | train_accuracy: 0.99749 | valid_accuracy: 0.93281 |  0:00:27s\n",
      "epoch 40 | loss: 0.01929 | train_accuracy: 0.99758 | valid_accuracy: 0.9315  |  0:00:28s\n",
      "epoch 41 | loss: 0.01905 | train_accuracy: 0.9977  | valid_accuracy: 0.93041 |  0:00:29s\n",
      "epoch 42 | loss: 0.02425 | train_accuracy: 0.99574 | valid_accuracy: 0.93194 |  0:00:29s\n",
      "epoch 43 | loss: 0.02699 | train_accuracy: 0.99666 | valid_accuracy: 0.93106 |  0:00:30s\n",
      "epoch 44 | loss: 0.02351 | train_accuracy: 0.99674 | valid_accuracy: 0.93455 |  0:00:31s\n",
      "epoch 45 | loss: 0.02437 | train_accuracy: 0.9967  | valid_accuracy: 0.93172 |  0:00:31s\n",
      "epoch 46 | loss: 0.023   | train_accuracy: 0.99549 | valid_accuracy: 0.92714 |  0:00:32s\n",
      "epoch 47 | loss: 0.02826 | train_accuracy: 0.99536 | valid_accuracy: 0.92801 |  0:00:33s\n",
      "epoch 48 | loss: 0.02483 | train_accuracy: 0.99578 | valid_accuracy: 0.92954 |  0:00:34s\n",
      "epoch 49 | loss: 0.02349 | train_accuracy: 0.99595 | valid_accuracy: 0.93237 |  0:00:34s\n",
      "epoch 50 | loss: 0.02484 | train_accuracy: 0.99733 | valid_accuracy: 0.93368 |  0:00:35s\n",
      "epoch 51 | loss: 0.02291 | train_accuracy: 0.99628 | valid_accuracy: 0.93019 |  0:00:36s\n",
      "epoch 52 | loss: 0.02313 | train_accuracy: 0.99682 | valid_accuracy: 0.93106 |  0:00:36s\n",
      "epoch 53 | loss: 0.02502 | train_accuracy: 0.99632 | valid_accuracy: 0.9315  |  0:00:37s\n",
      "epoch 54 | loss: 0.02493 | train_accuracy: 0.99674 | valid_accuracy: 0.93281 |  0:00:38s\n",
      "epoch 55 | loss: 0.02185 | train_accuracy: 0.99678 | valid_accuracy: 0.93259 |  0:00:39s\n",
      "epoch 56 | loss: 0.02272 | train_accuracy: 0.99712 | valid_accuracy: 0.93106 |  0:00:39s\n",
      "epoch 57 | loss: 0.0209  | train_accuracy: 0.99712 | valid_accuracy: 0.9315  |  0:00:40s\n",
      "epoch 58 | loss: 0.02137 | train_accuracy: 0.99783 | valid_accuracy: 0.93216 |  0:00:41s\n",
      "epoch 59 | loss: 0.01948 | train_accuracy: 0.99774 | valid_accuracy: 0.9339  |  0:00:41s\n",
      "epoch 60 | loss: 0.01861 | train_accuracy: 0.99812 | valid_accuracy: 0.93368 |  0:00:42s\n",
      "epoch 61 | loss: 0.01948 | train_accuracy: 0.99845 | valid_accuracy: 0.93565 |  0:00:43s\n",
      "epoch 62 | loss: 0.01643 | train_accuracy: 0.99833 | valid_accuracy: 0.93499 |  0:00:43s\n",
      "epoch 63 | loss: 0.0157  | train_accuracy: 0.99829 | valid_accuracy: 0.93521 |  0:00:44s\n",
      "epoch 64 | loss: 0.01528 | train_accuracy: 0.99896 | valid_accuracy: 0.93586 |  0:00:45s\n",
      "epoch 65 | loss: 0.01491 | train_accuracy: 0.99908 | valid_accuracy: 0.93586 |  0:00:45s\n",
      "epoch 66 | loss: 0.01436 | train_accuracy: 0.99912 | valid_accuracy: 0.93652 |  0:00:46s\n",
      "epoch 67 | loss: 0.01287 | train_accuracy: 0.99896 | valid_accuracy: 0.93412 |  0:00:47s\n",
      "epoch 68 | loss: 0.01208 | train_accuracy: 0.99908 | valid_accuracy: 0.93695 |  0:00:47s\n",
      "epoch 69 | loss: 0.01314 | train_accuracy: 0.99925 | valid_accuracy: 0.93586 |  0:00:48s\n",
      "epoch 70 | loss: 0.01178 | train_accuracy: 0.99925 | valid_accuracy: 0.93652 |  0:00:49s\n",
      "epoch 71 | loss: 0.01149 | train_accuracy: 0.99941 | valid_accuracy: 0.93739 |  0:00:50s\n",
      "epoch 72 | loss: 0.0123  | train_accuracy: 0.99929 | valid_accuracy: 0.93565 |  0:00:50s\n",
      "epoch 73 | loss: 0.01118 | train_accuracy: 0.99929 | valid_accuracy: 0.93565 |  0:00:51s\n",
      "epoch 74 | loss: 0.01224 | train_accuracy: 0.99916 | valid_accuracy: 0.93783 |  0:00:52s\n",
      "epoch 75 | loss: 0.01145 | train_accuracy: 0.99921 | valid_accuracy: 0.93674 |  0:00:52s\n",
      "epoch 76 | loss: 0.01189 | train_accuracy: 0.99925 | valid_accuracy: 0.93608 |  0:00:53s\n",
      "epoch 77 | loss: 0.01167 | train_accuracy: 0.99941 | valid_accuracy: 0.93674 |  0:00:54s\n",
      "epoch 78 | loss: 0.01088 | train_accuracy: 0.99929 | valid_accuracy: 0.93543 |  0:00:54s\n",
      "epoch 79 | loss: 0.01043 | train_accuracy: 0.99875 | valid_accuracy: 0.93477 |  0:00:55s\n",
      "epoch 80 | loss: 0.0138  | train_accuracy: 0.99854 | valid_accuracy: 0.93499 |  0:00:56s\n",
      "epoch 81 | loss: 0.01503 | train_accuracy: 0.99845 | valid_accuracy: 0.93368 |  0:00:56s\n",
      "epoch 82 | loss: 0.01338 | train_accuracy: 0.99891 | valid_accuracy: 0.93565 |  0:00:57s\n",
      "epoch 83 | loss: 0.01155 | train_accuracy: 0.99875 | valid_accuracy: 0.93412 |  0:00:58s\n",
      "epoch 84 | loss: 0.01197 | train_accuracy: 0.99887 | valid_accuracy: 0.9363  |  0:00:58s\n",
      "epoch 85 | loss: 0.01145 | train_accuracy: 0.99837 | valid_accuracy: 0.93128 |  0:00:59s\n",
      "epoch 86 | loss: 0.01316 | train_accuracy: 0.99925 | valid_accuracy: 0.93434 |  0:01:00s\n",
      "epoch 87 | loss: 0.01135 | train_accuracy: 0.99891 | valid_accuracy: 0.93346 |  0:01:01s\n",
      "epoch 88 | loss: 0.01224 | train_accuracy: 0.99891 | valid_accuracy: 0.93172 |  0:01:01s\n",
      "epoch 89 | loss: 0.01216 | train_accuracy: 0.99904 | valid_accuracy: 0.93368 |  0:01:02s\n",
      "epoch 90 | loss: 0.01061 | train_accuracy: 0.999   | valid_accuracy: 0.93565 |  0:01:03s\n",
      "epoch 91 | loss: 0.0117  | train_accuracy: 0.99929 | valid_accuracy: 0.93477 |  0:01:03s\n",
      "epoch 92 | loss: 0.01036 | train_accuracy: 0.99933 | valid_accuracy: 0.93565 |  0:01:04s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.00954 | train_accuracy: 0.99958 | valid_accuracy: 0.93499 |  0:01:05s\n",
      "epoch 94 | loss: 0.00934 | train_accuracy: 0.99954 | valid_accuracy: 0.93477 |  0:01:05s\n",
      "epoch 95 | loss: 0.00891 | train_accuracy: 0.99958 | valid_accuracy: 0.93695 |  0:01:06s\n",
      "epoch 96 | loss: 0.00909 | train_accuracy: 0.99937 | valid_accuracy: 0.9363  |  0:01:07s\n",
      "epoch 97 | loss: 0.00904 | train_accuracy: 0.99962 | valid_accuracy: 0.93695 |  0:01:07s\n",
      "epoch 98 | loss: 0.00845 | train_accuracy: 0.99962 | valid_accuracy: 0.93848 |  0:01:08s\n",
      "epoch 99 | loss: 0.00874 | train_accuracy: 0.99954 | valid_accuracy: 0.93608 |  0:01:09s\n",
      "Stop training because you reached max_epochs = 100 with best_epoch = 98 and best_valid_accuracy = 0.93848\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)], #(X_validx, y_validx)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    max_epochs=100, patience=100,\n",
    "    batch_size=16384, virtual_batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21e42aa370>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21e40cbc10>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "plt.plot(clf.history['train_accuracy'])\n",
    "plt.plot(clf.history['valid_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_dict = {0:1, 1:2, 2:3, 3:5, 4:6, 5:8, 6:10, 7:11, 8:12, 9:13, 10:15, 11:16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_dict(ar, dic):\n",
    "    # Extract out keys and values\n",
    "    k = np.array(list(dic.keys()))\n",
    "    v = np.array(list(dic.values()))\n",
    "\n",
    "    # Get argsort indices\n",
    "    sidx = k.argsort()\n",
    "\n",
    "    # Drop the magic bomb with searchsorted to get the corresponding\n",
    "    # places for a in keys (using sorter since a is not necessarily sorted).\n",
    "    # Then trace it back to original order with indexing into sidx\n",
    "    # Finally index into values for desired output.\n",
    "    return v[sidx[np.searchsorted(k,ar,sorter=sidx)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = replace_with_dict(y_preds, crop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VALID SCORE FOR : 0.9481821980777267\n",
      "FINAL TEST SCORE FOR : 0.9081588132635253\n"
     ]
    }
   ],
   "source": [
    "test_acc = accuracy_score(y_pred=y_preds, y_true=y_test)\n",
    "\n",
    "print(f\"BEST VALID SCORE FOR : {clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR : {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>B02_0322</th>\n",
       "      <th>B03_0322</th>\n",
       "      <th>B04_0322</th>\n",
       "      <th>B05_0322</th>\n",
       "      <th>B06_0322</th>\n",
       "      <th>B07_0322</th>\n",
       "      <th>B08A_0322</th>\n",
       "      <th>B08_0322</th>\n",
       "      <th>B11_0322</th>\n",
       "      <th>...</th>\n",
       "      <th>VH_20180905</th>\n",
       "      <th>VV_20180905</th>\n",
       "      <th>VH_20180913</th>\n",
       "      <th>VV_20180913</th>\n",
       "      <th>VH_20180917</th>\n",
       "      <th>VV_20180917</th>\n",
       "      <th>VH_20180925</th>\n",
       "      <th>VV_20180925</th>\n",
       "      <th>VH_20180929</th>\n",
       "      <th>VV_20180929</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crop_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geometry  B02_0322  B03_0322  B04_0322  B05_0322  B06_0322  B07_0322  \\\n",
       "crop_id                                                                         \n",
       "1             100       100       100       100       100       100       100   \n",
       "2             100       100       100       100       100       100       100   \n",
       "3             100       100       100       100       100       100       100   \n",
       "5             100       100       100       100       100       100       100   \n",
       "6             100       100       100       100       100       100       100   \n",
       "8             100       100       100       100       100       100       100   \n",
       "10            100       100       100       100       100       100       100   \n",
       "11            100       100       100       100       100       100       100   \n",
       "12            100       100       100       100       100       100       100   \n",
       "13            100       100       100       100       100       100       100   \n",
       "15            100       100       100       100       100       100       100   \n",
       "16            100       100       100       100       100       100       100   \n",
       "\n",
       "         B08A_0322  B08_0322  B11_0322  ...  VH_20180905  VV_20180905  \\\n",
       "crop_id                                 ...                             \n",
       "1              100       100       100  ...          100          100   \n",
       "2              100       100       100  ...          100          100   \n",
       "3              100       100       100  ...          100          100   \n",
       "5              100       100       100  ...          100          100   \n",
       "6              100       100       100  ...          100          100   \n",
       "8              100       100       100  ...          100          100   \n",
       "10             100       100       100  ...          100          100   \n",
       "11             100       100       100  ...          100          100   \n",
       "12             100       100       100  ...          100          100   \n",
       "13             100       100       100  ...          100          100   \n",
       "15             100       100       100  ...          100          100   \n",
       "16             100       100       100  ...          100          100   \n",
       "\n",
       "         VH_20180913  VV_20180913  VH_20180917  VV_20180917  VH_20180925  \\\n",
       "crop_id                                                                    \n",
       "1                100          100          100          100          100   \n",
       "2                100          100          100          100          100   \n",
       "3                100          100          100          100          100   \n",
       "5                100          100          100          100          100   \n",
       "6                100          100          100          100          100   \n",
       "8                100          100          100          100          100   \n",
       "10               100          100          100          100          100   \n",
       "11               100          100          100          100          100   \n",
       "12               100          100          100          100          100   \n",
       "13               100          100          100          100          100   \n",
       "15               100          100          100          100          100   \n",
       "16               100          100          100          100          100   \n",
       "\n",
       "         VV_20180925  VH_20180929  VV_20180929  \n",
       "crop_id                                         \n",
       "1                100          100          100  \n",
       "2                100          100          100  \n",
       "3                100          100          100  \n",
       "5                100          100          100  \n",
       "6                100          100          100  \n",
       "8                100          100          100  \n",
       "10               100          100          100  \n",
       "11               100          100          100  \n",
       "12               100          100          100  \n",
       "13               100          100          100  \n",
       "15               100          100          100  \n",
       "16               100          100          100  \n",
       "\n",
       "[12 rows x 240 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['crop_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>B02_0322</th>\n",
       "      <th>B03_0322</th>\n",
       "      <th>B04_0322</th>\n",
       "      <th>B05_0322</th>\n",
       "      <th>B06_0322</th>\n",
       "      <th>B07_0322</th>\n",
       "      <th>B08A_0322</th>\n",
       "      <th>B08_0322</th>\n",
       "      <th>B11_0322</th>\n",
       "      <th>...</th>\n",
       "      <th>VH_20180905</th>\n",
       "      <th>VV_20180905</th>\n",
       "      <th>VH_20180913</th>\n",
       "      <th>VV_20180913</th>\n",
       "      <th>VH_20180917</th>\n",
       "      <th>VV_20180917</th>\n",
       "      <th>VH_20180925</th>\n",
       "      <th>VV_20180925</th>\n",
       "      <th>VH_20180929</th>\n",
       "      <th>VV_20180929</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crop_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows  240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geometry  B02_0322  B03_0322  B04_0322  B05_0322  B06_0322  B07_0322  \\\n",
       "crop_id                                                                         \n",
       "1             400       400       400       400       400       400       400   \n",
       "2             400       400       400       400       400       400       400   \n",
       "3             400       400       400       400       400       400       400   \n",
       "5             400       400       400       400       400       400       400   \n",
       "6             400       400       400       400       400       400       400   \n",
       "8             400       400       400       400       400       400       400   \n",
       "10            400       400       400       400       400       400       400   \n",
       "11            400       400       400       400       400       400       400   \n",
       "12            400       400       400       400       400       400       400   \n",
       "13            400       400       400       400       400       400       400   \n",
       "15            380       380       380       380       380       380       380   \n",
       "16            204       204       204       204       204       204       204   \n",
       "\n",
       "         B08A_0322  B08_0322  B11_0322  ...  VH_20180905  VV_20180905  \\\n",
       "crop_id                                 ...                             \n",
       "1              400       400       400  ...          400          400   \n",
       "2              400       400       400  ...          400          400   \n",
       "3              400       400       400  ...          400          400   \n",
       "5              400       400       400  ...          400          400   \n",
       "6              400       400       400  ...          400          400   \n",
       "8              400       400       400  ...          400          400   \n",
       "10             400       400       400  ...          400          400   \n",
       "11             400       400       400  ...          400          400   \n",
       "12             400       400       400  ...          400          400   \n",
       "13             400       400       400  ...          400          400   \n",
       "15             380       380       380  ...          380          380   \n",
       "16             204       204       204  ...          204          204   \n",
       "\n",
       "         VH_20180913  VV_20180913  VH_20180917  VV_20180917  VH_20180925  \\\n",
       "crop_id                                                                    \n",
       "1                400          400          400          400          400   \n",
       "2                400          400          400          400          400   \n",
       "3                400          400          400          400          400   \n",
       "5                400          400          400          400          400   \n",
       "6                400          400          400          400          400   \n",
       "8                400          400          400          400          400   \n",
       "10               400          400          400          400          400   \n",
       "11               400          400          400          400          400   \n",
       "12               400          400          400          400          400   \n",
       "13               400          400          400          400          400   \n",
       "15               380          380          380          380          380   \n",
       "16               204          204          204          204          204   \n",
       "\n",
       "         VV_20180925  VH_20180929  VV_20180929  \n",
       "crop_id                                         \n",
       "1                400          400          400  \n",
       "2                400          400          400  \n",
       "3                400          400          400  \n",
       "5                400          400          400  \n",
       "6                400          400          400  \n",
       "8                400          400          400  \n",
       "10               400          400          400  \n",
       "11               400          400          400  \n",
       "12               400          400          400  \n",
       "13               400          400          400  \n",
       "15               380          380          380  \n",
       "16               204          204          204  \n",
       "\n",
       "[12 rows x 240 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(['crop_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5784"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1200+4584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
