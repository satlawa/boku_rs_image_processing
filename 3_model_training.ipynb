{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nice Formatting within Jupyter Notebook\n",
    "%matplotlib inline\n",
    "#from IPython.display import display # Allows multiple displays from a single code-cell\n",
    "\n",
    "# System functionality\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import Here any Additional modules you use. To import utilities we provide, use something like:\n",
    "#   from utils.plotter import plot_hinton\n",
    "\n",
    "# Your Code goes here:\n",
    "#from __future__ import division, print_function # Imports from __future__ since we're running Python 2\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split #, KFold\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from sklearn import preprocessing\n",
    "from numpy import unravel_index\n",
    "from matplotlib.colors import ListedColormap\n",
    "from numpy import linspace\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column noames to filter for experiments\n",
    "\n",
    "LAI = ['LAI_0322', 'LAI_0421', 'LAI_0513', 'LAI_0617', \n",
    "       'LAI_0702', 'LAI_0720', 'LAI_0809', 'LAI_0821', 'LAI_0920']\n",
    "\n",
    "S2 = ['B02_0322', 'B03_0322', 'B04_0322', 'B05_0322',\n",
    "       'B06_0322', 'B07_0322', 'B08A_0322', 'B08_0322', 'B11_0322', 'B12_0322',\n",
    "       'B02_0421', 'B03_0421', 'B04_0421', 'B05_0421', 'B06_0421',\n",
    "       'B07_0421', 'B08A_0421', 'B08_0421', 'B11_0421', 'B12_0421',\n",
    "       'B02_0513', 'B03_0513', 'B04_0513', 'B05_0513', 'B06_0513', 'B07_0513',\n",
    "       'B08A_0513', 'B08_0513', 'B11_0513', 'B12_0513', 'B02_0617',\n",
    "       'B03_0617', 'B04_0617', 'B05_0617', 'B06_0617', 'B07_0617', 'B08A_0617',\n",
    "       'B08_0617', 'B11_0617', 'B12_0617', 'B02_0702', 'B03_0702',\n",
    "       'B04_0702', 'B05_0702', 'B06_0702', 'B07_0702', 'B08A_0702', 'B08_0702',\n",
    "       'B11_0702', 'B12_0702', 'B02_0720', 'B03_0720', 'B04_0720',\n",
    "       'B05_0720', 'B06_0720', 'B07_0720', 'B08A_0720', 'B08_0720', 'B11_0720',\n",
    "       'B12_0720', 'B02_0809', 'B03_0809', 'B04_0809', 'B05_0809',\n",
    "       'B06_0809', 'B07_0809', 'B08A_0809', 'B08_0809', 'B11_0809', 'B12_0809',\n",
    "       'B02_0821', 'B03_0821', 'B04_0821', 'B05_0821', 'B06_0821',\n",
    "       'B07_0821', 'B08A.jp_0821', 'B08_0821', 'B11_0821', 'B12_0821',\n",
    "       'B02_0920', 'B03_0920', 'B04_0920', 'B05_0920', 'B06_0920',\n",
    "       'B07_0920', 'B08A_0920', 'B08_0920', 'B11_0920', 'B12_0920']\n",
    "\n",
    "S1 = ['VH_20180303', 'VV_20180303', 'VH_20180311', 'VV_20180311',\n",
    "       'VH_20180315', 'VV_20180315', 'VH_20180323', 'VV_20180323',\n",
    "       'VH_20180327', 'VV_20180327', 'VH_20180404', 'VV_20180404',\n",
    "       'VH_20180408', 'VV_20180408', 'VH_20180416', 'VV_20180416',\n",
    "       'VH_20180420', 'VV_20180420', 'VH_20180428', 'VV_20180428',\n",
    "       'VH_20180502', 'VV_20180502', 'VH_20180510', 'VV_20180510',\n",
    "       'VH_20180522', 'VV_20180522', 'VH_20180526', 'VV_20180526',\n",
    "       'VH_20180603', 'VV_20180603', 'VH_20180607', 'VV_20180607',\n",
    "       'VH_20180615', 'VV_20180615', 'VH_20180619', 'VV_20180619',\n",
    "       'VH_20180627', 'VV_20180627', 'VH_20180701', 'VV_20180701',\n",
    "       'VH_20180709', 'VV_20180709', 'VH_20180713', 'VV_20180713',\n",
    "       'VH_20180721', 'VV_20180721', 'VH_20180725', 'VV_20180725',\n",
    "       'VH_20180802', 'VV_20180802', 'VH_20180806', 'VV_20180806',\n",
    "       'VH_20180814', 'VV_20180814', 'VH_20180818', 'VV_20180818',\n",
    "       'VH_20180826', 'VV_20180826', 'VH_20180830', 'VV_20180830',\n",
    "       'VH_20180907', 'VV_20180907', 'VH_20180911', 'VV_20180911',\n",
    "       'VH_20180919', 'VV_20180919', 'VH_20180923', 'VV_20180923',\n",
    "       'VH_20180305', 'VV_20180305', 'VH_20180309', 'VV_20180309',\n",
    "       'VH_20180317', 'VV_20180317', 'VH_20180321', 'VV_20180321',\n",
    "       'VH_20180329', 'VV_20180329', 'VH_20180402', 'VV_20180402',\n",
    "       'VH_20180410', 'VV_20180410', 'VH_20180414', 'VV_20180414',\n",
    "       'VH_20180422', 'VV_20180422', 'VH_20180426', 'VV_20180426',\n",
    "       'VH_20180504', 'VV_20180504', 'VH_20180508', 'VV_20180508',\n",
    "       'VH_20180516', 'VV_20180516', 'VH_20180520', 'VV_20180520',\n",
    "       'VH_20180528', 'VV_20180528', 'VH_20180601', 'VV_20180601', \n",
    "       'VH_20180609', 'VV_20180609', 'VH_20180613', 'VV_20180613', \n",
    "       'VH_20180621', 'VV_20180621', 'VH_20180625',\n",
    "       'VV_20180625', 'VH_20180703', 'VV_20180703', 'VH_20180707',\n",
    "       'VV_20180707', 'VH_20180715', 'VV_20180715', 'VH_20180719',\n",
    "       'VV_20180719', 'VH_20180727', 'VV_20180727', 'VH_20180731',\n",
    "       'VV_20180731', 'VH_20180808', 'VV_20180808', 'VH_20180812',\n",
    "       'VV_20180812', 'VH_20180820', 'VV_20180820', 'VH_20180824',\n",
    "       'VV_20180824', 'VH_20180901', 'VV_20180901', 'VH_20180905',\n",
    "       'VV_20180905', 'VH_20180913', 'VV_20180913', 'VH_20180917',\n",
    "       'VV_20180917', 'VH_20180925', 'VV_20180925', 'VH_20180929',\n",
    "       'VV_20180929'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "###   load data   ###\n",
    "#####################\n",
    "\n",
    "# load datasets\n",
    "data_path = \"/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s1_s2_raster/data/train_data_ext.csv\"\n",
    "train_org = pd.read_csv(data_path, delimiter = ',', index_col=0)\n",
    "data_path = \"/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s1_s2_raster/data/test_data.csv\"\n",
    "test_org = pd.read_csv(data_path, delimiter = ',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: number of instances: 23930, number of attributes: 92\n",
      "Test: number of instances: 4584, number of attributes: 92\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "###   preprocess data   ###\n",
    "###########################\n",
    "\n",
    "experiment = S2\n",
    "\n",
    "# filter for experiments\n",
    "train = train_org[['crop_id', 'geometry'] + experiment]\n",
    "test = test_org[['crop_id', 'geometry'] + experiment]\n",
    "\n",
    "train = shuffle(train, random_state=399)\n",
    "\n",
    "X_train = train.drop(['crop_id','geometry'], axis=1).values\n",
    "y_train = train['crop_id'].values\n",
    "X_test = test.drop(['crop_id','geometry'], axis=1).values\n",
    "y_test = test['crop_id'].values\n",
    "\n",
    "print(\"Train: number of instances: {}, number of attributes: {}\".format(train.shape[0], train.shape[1]))\n",
    "print(\"Test: number of instances: {}, number of attributes: {}\".format(test.shape[0], test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "###   exploring data   ###\n",
    "##########################\n",
    "\n",
    "#print(train.head(7))\n",
    "\n",
    "#train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "###   standardize data   ###\n",
    "############################\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\n",
    "##########################\n",
    "###                    ###\n",
    "###   Classification   ###\n",
    "###                    ###\n",
    "##########################\n",
    "##########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "###   RFC - Random Forest Classifier   ###\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8777684914333472 [0.87379858 0.88090263 0.8817384  0.86711241 0.87797743 0.88215629\n",
      " 0.88090263 0.87964898 0.86627664 0.88717092]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(criterion='entropy', max_depth=100, max_features='sqrt', n_estimators=100, \\\n",
    "                             min_samples_split=2, random_state=399, n_jobs=8)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "print(np.mean(scores), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'n_estimators': [100], 'criterion': ['entropy'], \\\n",
    "     'max_depth': [None, 100, 1000], 'max_features': ['sqrt', 'log2'], },\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=RandomForestClassifier(), n_jobs=8,\n",
       "             param_grid=[{'criterion': ['entropy'],\n",
       "                          'max_depth': [None, 100, 1000],\n",
       "                          'max_features': ['sqrt', 'log2'],\n",
       "                          'n_estimators': [100]}])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(RandomForestClassifier(), param_grid, cv=10, n_jobs=8)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best parameters set found on development set:  {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "\n",
      "Best mean cross-validated score: 0.7916666666666666\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Grid scores for SVM:\n",
      "\n",
      "0.788 (+/-0.056) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.783 (+/-0.048) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.792 (+/-0.075) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.776 (+/-0.046) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.778 (+/-0.061) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.791 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 100}\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Best parameters set found on development set: \", clf.best_params_)\n",
    "print()\n",
    "print('Best mean cross-validated score:', clf.best_score_)\n",
    "print()\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Grid scores for SVM:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print(\"------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[330  14   2  20   1  11   6   2   0   7   1   6]\n",
      " [  3 388   1   1   3   1   2   0   0   1   0   0]\n",
      " [  1   0 388   1   0   0   0   0   0   7   1   2]\n",
      " [ 37  17  19 241   9   9  10   0   4  19  21  14]\n",
      " [  2  30   1   3 284  29  10  22   0   1  18   0]\n",
      " [  9  10   0  13  13 325  12  10   0   0   0   8]\n",
      " [  8   8   0   2  11  21 338  12   0   0   0   0]\n",
      " [  1   5   0   2  17  10  22 343   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 391   0   9   0]\n",
      " [ 21   0   5   0   1   0   2   1   0 343   5  22]\n",
      " [  2   0   0   1   2   0   0   0   1   1 373   0]\n",
      " [  3   0   0   1   0   0   0   0   0   2   0 198]]\n",
      "0.8599476439790575\n"
     ]
    }
   ],
   "source": [
    "# prediction with the best preforming model\n",
    "clf = RandomForestClassifier(criterion='entropy', max_depth=100, max_features='sqrt', n_estimators=100)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best parameters set found on development set:  {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "\n",
      "Best mean cross-validated score: 0.8858333333333335\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Grid scores for SVM:\n",
      "\n",
      "0.653 (+/-0.124) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.825 (+/-0.074) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.883 (+/-0.044) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.882 (+/-0.061) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.632 (+/-0.060) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.814 (+/-0.061) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.879 (+/-0.053) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.883 (+/-0.052) for {'criterion': 'gini', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.731 (+/-0.068) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 1}\n",
      "0.823 (+/-0.092) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 10}\n",
      "0.843 (+/-0.082) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 100}\n",
      "0.848 (+/-0.080) for {'criterion': 'gini', 'max_depth': None, 'max_features': None, 'n_estimators': 1000}\n",
      "0.623 (+/-0.091) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.831 (+/-0.070) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.877 (+/-0.061) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.878 (+/-0.055) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.623 (+/-0.089) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.826 (+/-0.051) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.872 (+/-0.061) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.874 (+/-0.062) for {'criterion': 'gini', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.698 (+/-0.083) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 1}\n",
      "0.816 (+/-0.071) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 10}\n",
      "0.851 (+/-0.076) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 100}\n",
      "0.846 (+/-0.086) for {'criterion': 'gini', 'max_depth': 10, 'max_features': None, 'n_estimators': 1000}\n",
      "0.654 (+/-0.070) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.832 (+/-0.090) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.880 (+/-0.063) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.882 (+/-0.064) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.654 (+/-0.106) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.828 (+/-0.053) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.872 (+/-0.074) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.883 (+/-0.049) for {'criterion': 'gini', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.702 (+/-0.056) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 1}\n",
      "0.838 (+/-0.070) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 10}\n",
      "0.849 (+/-0.079) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 100}\n",
      "0.851 (+/-0.079) for {'criterion': 'gini', 'max_depth': 100, 'max_features': None, 'n_estimators': 1000}\n",
      "0.660 (+/-0.064) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.832 (+/-0.082) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.881 (+/-0.052) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.882 (+/-0.058) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.642 (+/-0.080) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.823 (+/-0.043) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.877 (+/-0.052) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.883 (+/-0.058) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.718 (+/-0.097) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1}\n",
      "0.822 (+/-0.081) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 10}\n",
      "0.855 (+/-0.084) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 100}\n",
      "0.849 (+/-0.078) for {'criterion': 'gini', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1000}\n",
      "0.648 (+/-0.095) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.830 (+/-0.045) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.873 (+/-0.067) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.884 (+/-0.047) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.655 (+/-0.059) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.828 (+/-0.057) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.881 (+/-0.054) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.882 (+/-0.046) for {'criterion': 'entropy', 'max_depth': None, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.728 (+/-0.083) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 1}\n",
      "0.832 (+/-0.059) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 10}\n",
      "0.855 (+/-0.075) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 100}\n",
      "0.856 (+/-0.061) for {'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'n_estimators': 1000}\n",
      "0.653 (+/-0.079) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.838 (+/-0.070) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.882 (+/-0.056) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.878 (+/-0.058) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.643 (+/-0.107) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.825 (+/-0.054) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.879 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.879 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.702 (+/-0.128) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 1}\n",
      "0.829 (+/-0.052) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 10}\n",
      "0.853 (+/-0.058) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 100}\n",
      "0.857 (+/-0.071) for {'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'n_estimators': 1000}\n",
      "0.659 (+/-0.070) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.835 (+/-0.070) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.883 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.882 (+/-0.050) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.627 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.836 (+/-0.081) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.879 (+/-0.053) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.878 (+/-0.057) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.702 (+/-0.062) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 1}\n",
      "0.828 (+/-0.067) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 10}\n",
      "0.853 (+/-0.069) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 100}\n",
      "0.857 (+/-0.063) for {'criterion': 'entropy', 'max_depth': 100, 'max_features': None, 'n_estimators': 1000}\n",
      "0.647 (+/-0.108) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1}\n",
      "0.844 (+/-0.053) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 10}\n",
      "0.886 (+/-0.045) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 100}\n",
      "0.876 (+/-0.059) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'sqrt', 'n_estimators': 1000}\n",
      "0.628 (+/-0.101) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1}\n",
      "0.828 (+/-0.058) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 10}\n",
      "0.885 (+/-0.048) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 100}\n",
      "0.881 (+/-0.058) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': 'log2', 'n_estimators': 1000}\n",
      "0.711 (+/-0.068) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1}\n",
      "0.832 (+/-0.068) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 10}\n",
      "0.857 (+/-0.062) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 100}\n",
      "0.855 (+/-0.064) for {'criterion': 'entropy', 'max_depth': 1000, 'max_features': None, 'n_estimators': 1000}\n",
      "------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Best parameters set found on development set: \", clf.best_params_)\n",
    "print()\n",
    "print('Best mean cross-validated score:', clf.best_score_)\n",
    "print()\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Grid scores for SVM:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))\n",
    "print(\"------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################\n",
    "###   SVC - Support Vector Classifier   ###\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9926870037609694 [0.99331383 0.99456749 0.99206018 0.99582115 0.9912244  0.99164229\n",
      " 0.99080652 0.99247806 0.98997075 0.99498537]\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='rbf', C=5, gamma='scale', random_state=399)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10, n_jobs=8)\n",
    "print(np.mean(scores), scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'], 'kernel': ['rbf']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'], 'degree': [2, 3, 4], 'kernel': ['poly']},\n",
    "    {'C': [1, 10, 100, 1000], 'gamma': ['scale', 'auto'], 'kernel': ['sigmoid']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'C': [10, 50, 100], 'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10], 'kernel': ['rbf']},\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=SVC(), n_jobs=8,\n",
       "             param_grid=[{'C': [10, 50, 100],\n",
       "                          'gamma': [0.0001, 0.001, 0.01, 0.1, 1, 10],\n",
       "                          'kernel': ['rbf']}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVC(), param_grid, cv=10, n_jobs=8)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Best parameters set found on development set:  {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "\n",
      "Best mean cross-validated score: 0.9133333333333334\n",
      "\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Grid scores for SVM:\n",
      "\n",
      "0.888 (+/-0.047) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.913 (+/-0.020) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.885 (+/-0.053) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.282 (+/-0.054) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.138 (+/-0.117) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.092 (+/-0.018) for {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.904 (+/-0.017) for {'C': 50, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.913 (+/-0.027) for {'C': 50, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.885 (+/-0.053) for {'C': 50, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.282 (+/-0.054) for {'C': 50, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.138 (+/-0.117) for {'C': 50, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.092 (+/-0.018) for {'C': 50, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.903 (+/-0.017) for {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "0.913 (+/-0.027) for {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "0.885 (+/-0.053) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.282 (+/-0.054) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.138 (+/-0.117) for {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.092 (+/-0.018) for {'C': 100, 'gamma': 10, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print()\n",
    "print(\"Best parameters set found on development set: \", clf.best_params_)\n",
    "print()\n",
    "print('Best mean cross-validated score:', clf.best_score_)\n",
    "print()\n",
    "print(\"------------------------------------------------------------------------------------------------------\")\n",
    "print(\"Grid scores for SVM:\")\n",
    "print()\n",
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "          % (mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "###   Prediction   ###\n",
    "######################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[379   1   2   3   2   6   1   3   0   1   1   1]\n",
      " [  3 382   0   8   4   0   1   0   0   2   0   0]\n",
      " [  0   0 380   3   2   1   0   0   8   1   5   0]\n",
      " [ 17   9   4 325  13   3   0   6   0   4  16   3]\n",
      " [  1   7   1   9 341   2   6  15   0   5  13   0]\n",
      " [ 14   1   0  11   4 363   2   1   0   3   1   0]\n",
      " [  1   0   0   5   3   3 382   2   0   4   0   0]\n",
      " [  1   1   0   2  17   1   2 372   0   1   3   0]\n",
      " [  0   0   3   1   0   0   0   0 385   4   6   1]\n",
      " [  1   0   2   0   0   0   0   2   0 384   4   7]\n",
      " [  3   0   1   0   3   0   0   0   0   0 373   0]\n",
      " [  0   0   0   0   0   0   0   0   0   2   0 202]]\n",
      "0.931064572425829\n"
     ]
    }
   ],
   "source": [
    "# prediction with the best preforming model\n",
    "clf = SVC(kernel='rbf', C=5, gamma='scale', random_state=399)\n",
    "clf.fit(X_train, y_train)\n",
    "pred = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test, pred))\n",
    "print(accuracy_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classification ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s2_raster/data/class_data_3.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s2_raster/data/class_data_3.npy', data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6400000, 90)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s2_raster/data/class_data_1.npy', data_01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scaler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/media/philipp/ed7d22ba-5a3b-4d31-bf6c-6add6e106b3d/crops/s2_raster/data/pred_data_3.npy', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[379,   1,   2,   3,   2,   6,   1,   3,   0,   1,   1,   1],\n",
       "       [  3, 382,   0,   8,   4,   0,   1,   0,   0,   2,   0,   0],\n",
       "       [  0,   0, 380,   3,   2,   1,   0,   0,   8,   1,   5,   0],\n",
       "       [ 17,   9,   4, 325,  13,   3,   0,   6,   0,   4,  16,   3],\n",
       "       [  1,   7,   1,   9, 341,   2,   6,  15,   0,   5,  13,   0],\n",
       "       [ 14,   1,   0,  11,   4, 363,   2,   1,   0,   3,   1,   0],\n",
       "       [  1,   0,   0,   5,   3,   3, 382,   2,   0,   4,   0,   0],\n",
       "       [  1,   1,   0,   2,  17,   1,   2, 372,   0,   1,   3,   0],\n",
       "       [  0,   0,   3,   1,   0,   0,   0,   0, 385,   4,   6,   1],\n",
       "       [  1,   0,   2,   0,   0,   0,   0,   2,   0, 384,   4,   7],\n",
       "       [  3,   0,   1,   0,   3,   0,   0,   0,   0,   0, 373,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   2,   0, 202]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931064572425829"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ext LAI+S1+S2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[376,   0,   2,  10,   1,   6,   2,   2,   0,   0,   0,   1],\n",
       "       [  4, 389,   0,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 396,   2,   0,   0,   0,   0,   0,   1,   1,   0],\n",
       "       [  6,   7,   6, 345,   7,   0,   1,   1,   2,   6,  16,   3],\n",
       "       [  0,  11,   0,   5, 355,   1,   9,   5,   0,   0,  14,   0],\n",
       "       [  5,   2,   0,   9,   2, 381,   0,   0,   0,   0,   0,   1],\n",
       "       [  1,   0,   0,   2,   1,   4, 392,   0,   0,   0,   0,   0],\n",
       "       [  1,   0,   0,   1,   7,   0,   1, 389,   0,   0,   1,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 396,   0,   4,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   2,   0, 394,   3,   1],\n",
       "       [  3,   0,   0,   1,   4,   0,   0,   0,   0,   0, 372,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 204]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9574607329842932"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-tabnet\n",
      "  Using cached pytorch_tabnet-3.1.1-py3-none-any.whl (39 kB)\n",
      "Processing /home/philipp/.cache/pip/wheels/bd/a8/c3/3cf2c14a1837a4e04bd98631724e81f33f462d86a1d895fae0/wget-3.2-py3-none-any.whl\n",
      "Requirement already satisfied: tqdm<5.0,>=4.36 in /home/philipp/.local/lib/python3.8/site-packages (from pytorch-tabnet) (4.61.0)\n",
      "Requirement already satisfied: scipy>1.4 in /home/philipp/.local/lib/python3.8/site-packages (from pytorch-tabnet) (1.7.0)\n",
      "Requirement already satisfied: scikit_learn>0.21 in /home/philipp/.local/lib/python3.8/site-packages (from pytorch-tabnet) (0.24.2)\n",
      "Collecting torch<2.0,>=1.2\n",
      "  Using cached torch-1.9.0-cp38-cp38-manylinux1_x86_64.whl (831.4 MB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/lib/python3/dist-packages (from pytorch-tabnet) (1.17.4)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/philipp/.local/lib/python3.8/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/philipp/.local/lib/python3.8/site-packages (from scikit_learn>0.21->pytorch-tabnet) (2.1.0)\n",
      "Requirement already satisfied: typing-extensions in /home/philipp/.local/lib/python3.8/site-packages (from torch<2.0,>=1.2->pytorch-tabnet) (3.10.0.0)\n",
      "Installing collected packages: torch, pytorch-tabnet, wget\n",
      "Successfully installed pytorch-tabnet-3.1.1 torch-1.9.0 wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-tabnet wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = round(X_train.shape[0]*0.9)\n",
    "\n",
    "X_trainx = X_train[:l]\n",
    "y_trainx = y_train[:l]\n",
    "\n",
    "X_validx = X_train[l:]\n",
    "y_validx = y_train[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device used : cuda\n"
     ]
    }
   ],
   "source": [
    "# network parameters\n",
    "clf = TabNetClassifier(\n",
    "    n_d=16, n_a=16, n_steps=5,\n",
    "    gamma=1.5, n_independent=2, n_shared=2,\n",
    "    #cat_idxs=cat_idxs,\n",
    "    #cat_dims=cat_dims,\n",
    "    cat_emb_dim=1,\n",
    "    lambda_sparse=1e-2, momentum=0.3, #clip_value=2.,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    scheduler_params = {\"gamma\": 0.95,\n",
    "                     \"step_size\": 20},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR, epsilon=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.62001 | train_accuracy: 0.09636 | valid_accuracy: 0.10406 |  0:00:00s\n",
      "epoch 1  | loss: 3.11225 | train_accuracy: 0.11112 | valid_accuracy: 0.1082  |  0:00:01s\n",
      "epoch 2  | loss: 2.8784  | train_accuracy: 0.12344 | valid_accuracy: 0.12609 |  0:00:02s\n",
      "epoch 3  | loss: 2.70047 | train_accuracy: 0.13974 | valid_accuracy: 0.14463 |  0:00:02s\n",
      "epoch 4  | loss: 2.59303 | train_accuracy: 0.16072 | valid_accuracy: 0.16165 |  0:00:03s\n",
      "epoch 5  | loss: 2.47291 | train_accuracy: 0.17626 | valid_accuracy: 0.19023 |  0:00:03s\n",
      "epoch 6  | loss: 2.38587 | train_accuracy: 0.21162 | valid_accuracy: 0.21597 |  0:00:04s\n",
      "epoch 7  | loss: 2.28499 | train_accuracy: 0.2303  | valid_accuracy: 0.23168 |  0:00:05s\n",
      "epoch 8  | loss: 2.1884  | train_accuracy: 0.26515 | valid_accuracy: 0.25218 |  0:00:05s\n",
      "epoch 9  | loss: 2.10031 | train_accuracy: 0.28834 | valid_accuracy: 0.2836  |  0:00:06s\n",
      "epoch 10 | loss: 2.0257  | train_accuracy: 0.30823 | valid_accuracy: 0.30694 |  0:00:07s\n",
      "epoch 11 | loss: 1.95315 | train_accuracy: 0.32913 | valid_accuracy: 0.32548 |  0:00:07s\n",
      "epoch 12 | loss: 1.89459 | train_accuracy: 0.34066 | valid_accuracy: 0.33988 |  0:00:08s\n",
      "epoch 13 | loss: 1.8525  | train_accuracy: 0.3509  | valid_accuracy: 0.35166 |  0:00:09s\n",
      "epoch 14 | loss: 1.80786 | train_accuracy: 0.36565 | valid_accuracy: 0.37129 |  0:00:09s\n",
      "epoch 15 | loss: 1.78592 | train_accuracy: 0.36895 | valid_accuracy: 0.38416 |  0:00:10s\n",
      "epoch 16 | loss: 1.75683 | train_accuracy: 0.38554 | valid_accuracy: 0.38743 |  0:00:10s\n",
      "epoch 17 | loss: 1.71853 | train_accuracy: 0.40059 | valid_accuracy: 0.40205 |  0:00:11s\n",
      "epoch 18 | loss: 1.67457 | train_accuracy: 0.40715 | valid_accuracy: 0.41885 |  0:00:12s\n",
      "epoch 19 | loss: 1.65603 | train_accuracy: 0.42148 | valid_accuracy: 0.42627 |  0:00:12s\n",
      "epoch 20 | loss: 1.61808 | train_accuracy: 0.42645 | valid_accuracy: 0.42714 |  0:00:13s\n",
      "epoch 21 | loss: 1.60901 | train_accuracy: 0.43197 | valid_accuracy: 0.43805 |  0:00:14s\n",
      "epoch 22 | loss: 1.58574 | train_accuracy: 0.43539 | valid_accuracy: 0.43521 |  0:00:14s\n",
      "epoch 23 | loss: 1.57927 | train_accuracy: 0.44338 | valid_accuracy: 0.44175 |  0:00:15s\n",
      "epoch 24 | loss: 1.56013 | train_accuracy: 0.4412  | valid_accuracy: 0.44001 |  0:00:15s\n",
      "epoch 25 | loss: 1.54091 | train_accuracy: 0.4537  | valid_accuracy: 0.45353 |  0:00:16s\n",
      "epoch 26 | loss: 1.51309 | train_accuracy: 0.46849 | valid_accuracy: 0.45812 |  0:00:17s\n",
      "epoch 27 | loss: 1.48212 | train_accuracy: 0.4756  | valid_accuracy: 0.47186 |  0:00:17s\n",
      "epoch 28 | loss: 1.45313 | train_accuracy: 0.49507 | valid_accuracy: 0.49847 |  0:00:18s\n",
      "epoch 29 | loss: 1.42519 | train_accuracy: 0.50669 | valid_accuracy: 0.50807 |  0:00:19s\n",
      "epoch 30 | loss: 1.40344 | train_accuracy: 0.51149 | valid_accuracy: 0.52291 |  0:00:19s\n",
      "epoch 31 | loss: 1.38968 | train_accuracy: 0.52081 | valid_accuracy: 0.5216  |  0:00:20s\n",
      "epoch 32 | loss: 1.38115 | train_accuracy: 0.52474 | valid_accuracy: 0.52029 |  0:00:20s\n",
      "epoch 33 | loss: 1.36159 | train_accuracy: 0.53527 | valid_accuracy: 0.53098 |  0:00:21s\n",
      "epoch 34 | loss: 1.34303 | train_accuracy: 0.53711 | valid_accuracy: 0.54625 |  0:00:22s\n",
      "epoch 35 | loss: 1.33794 | train_accuracy: 0.54116 | valid_accuracy: 0.53796 |  0:00:22s\n",
      "epoch 36 | loss: 1.32288 | train_accuracy: 0.54923 | valid_accuracy: 0.54363 |  0:00:23s\n",
      "epoch 37 | loss: 1.30285 | train_accuracy: 0.54162 | valid_accuracy: 0.5421  |  0:00:24s\n",
      "epoch 38 | loss: 1.31496 | train_accuracy: 0.54417 | valid_accuracy: 0.54603 |  0:00:25s\n",
      "epoch 39 | loss: 1.29069 | train_accuracy: 0.5532  | valid_accuracy: 0.55148 |  0:00:25s\n",
      "epoch 40 | loss: 1.28469 | train_accuracy: 0.55767 | valid_accuracy: 0.55563 |  0:00:26s\n",
      "epoch 41 | loss: 1.26448 | train_accuracy: 0.55788 | valid_accuracy: 0.55214 |  0:00:26s\n",
      "epoch 42 | loss: 1.26179 | train_accuracy: 0.56381 | valid_accuracy: 0.5541  |  0:00:27s\n",
      "epoch 43 | loss: 1.24946 | train_accuracy: 0.57158 | valid_accuracy: 0.55476 |  0:00:28s\n",
      "epoch 44 | loss: 1.23255 | train_accuracy: 0.57451 | valid_accuracy: 0.55934 |  0:00:28s\n",
      "epoch 45 | loss: 1.22281 | train_accuracy: 0.58291 | valid_accuracy: 0.57024 |  0:00:29s\n",
      "epoch 46 | loss: 1.19283 | train_accuracy: 0.58805 | valid_accuracy: 0.57504 |  0:00:30s\n",
      "epoch 47 | loss: 1.17712 | train_accuracy: 0.60242 | valid_accuracy: 0.58355 |  0:00:30s\n",
      "epoch 48 | loss: 1.15731 | train_accuracy: 0.60593 | valid_accuracy: 0.59359 |  0:00:31s\n",
      "epoch 49 | loss: 1.14306 | train_accuracy: 0.61333 | valid_accuracy: 0.60842 |  0:00:32s\n",
      "epoch 50 | loss: 1.13181 | train_accuracy: 0.61438 | valid_accuracy: 0.60471 |  0:00:32s\n",
      "epoch 51 | loss: 1.12131 | train_accuracy: 0.61525 | valid_accuracy: 0.61235 |  0:00:33s\n",
      "epoch 52 | loss: 1.11859 | train_accuracy: 0.61563 | valid_accuracy: 0.60188 |  0:00:34s\n",
      "epoch 53 | loss: 1.10893 | train_accuracy: 0.61672 | valid_accuracy: 0.61235 |  0:00:34s\n",
      "epoch 54 | loss: 1.10285 | train_accuracy: 0.62181 | valid_accuracy: 0.61911 |  0:00:35s\n",
      "epoch 55 | loss: 1.09897 | train_accuracy: 0.628   | valid_accuracy: 0.62914 |  0:00:36s\n",
      "epoch 56 | loss: 1.09245 | train_accuracy: 0.63088 | valid_accuracy: 0.62456 |  0:00:36s\n",
      "epoch 57 | loss: 1.08535 | train_accuracy: 0.63063 | valid_accuracy: 0.62805 |  0:00:37s\n",
      "epoch 58 | loss: 1.07477 | train_accuracy: 0.63372 | valid_accuracy: 0.6322  |  0:00:37s\n",
      "epoch 59 | loss: 1.06246 | train_accuracy: 0.63686 | valid_accuracy: 0.63569 |  0:00:38s\n",
      "epoch 60 | loss: 1.06483 | train_accuracy: 0.63819 | valid_accuracy: 0.62435 |  0:00:39s\n",
      "epoch 61 | loss: 1.05651 | train_accuracy: 0.64087 | valid_accuracy: 0.62195 |  0:00:39s\n",
      "epoch 62 | loss: 1.04964 | train_accuracy: 0.64434 | valid_accuracy: 0.63045 |  0:00:40s\n",
      "epoch 63 | loss: 1.03515 | train_accuracy: 0.65198 | valid_accuracy: 0.63787 |  0:00:41s\n",
      "epoch 64 | loss: 1.02556 | train_accuracy: 0.65357 | valid_accuracy: 0.63809 |  0:00:41s\n",
      "epoch 65 | loss: 1.01273 | train_accuracy: 0.65575 | valid_accuracy: 0.64769 |  0:00:42s\n",
      "epoch 66 | loss: 1.00247 | train_accuracy: 0.66034 | valid_accuracy: 0.66034 |  0:00:43s\n",
      "epoch 67 | loss: 0.99498 | train_accuracy: 0.66222 | valid_accuracy: 0.65707 |  0:00:43s\n",
      "epoch 68 | loss: 0.98699 | train_accuracy: 0.66582 | valid_accuracy: 0.66121 |  0:00:44s\n",
      "epoch 69 | loss: 0.97259 | train_accuracy: 0.67117 | valid_accuracy: 0.66099 |  0:00:44s\n",
      "epoch 70 | loss: 0.96307 | train_accuracy: 0.67585 | valid_accuracy: 0.66034 |  0:00:45s\n",
      "epoch 71 | loss: 0.95352 | train_accuracy: 0.67409 | valid_accuracy: 0.66383 |  0:00:46s\n",
      "epoch 72 | loss: 0.94715 | train_accuracy: 0.68094 | valid_accuracy: 0.66361 |  0:00:46s\n",
      "epoch 73 | loss: 0.93347 | train_accuracy: 0.68023 | valid_accuracy: 0.66361 |  0:00:47s\n",
      "epoch 74 | loss: 0.92884 | train_accuracy: 0.68759 | valid_accuracy: 0.6743  |  0:00:48s\n",
      "epoch 75 | loss: 0.92026 | train_accuracy: 0.69223 | valid_accuracy: 0.6815  |  0:00:48s\n",
      "epoch 76 | loss: 0.90858 | train_accuracy: 0.69315 | valid_accuracy: 0.67976 |  0:00:49s\n",
      "epoch 77 | loss: 0.90041 | train_accuracy: 0.69402 | valid_accuracy: 0.68128 |  0:00:50s\n",
      "epoch 78 | loss: 0.8952  | train_accuracy: 0.6985  | valid_accuracy: 0.68019 |  0:00:50s\n",
      "epoch 79 | loss: 0.89077 | train_accuracy: 0.69875 | valid_accuracy: 0.68194 |  0:00:51s\n",
      "epoch 80 | loss: 0.87804 | train_accuracy: 0.70138 | valid_accuracy: 0.68412 |  0:00:51s\n",
      "epoch 81 | loss: 0.86632 | train_accuracy: 0.70405 | valid_accuracy: 0.69175 |  0:00:52s\n",
      "epoch 82 | loss: 0.85463 | train_accuracy: 0.70995 | valid_accuracy: 0.69699 |  0:00:53s\n",
      "epoch 83 | loss: 0.84897 | train_accuracy: 0.71041 | valid_accuracy: 0.69852 |  0:00:53s\n",
      "epoch 84 | loss: 0.84108 | train_accuracy: 0.71755 | valid_accuracy: 0.70484 |  0:00:54s\n",
      "epoch 85 | loss: 0.83327 | train_accuracy: 0.71805 | valid_accuracy: 0.69786 |  0:00:55s\n",
      "epoch 86 | loss: 0.82815 | train_accuracy: 0.71642 | valid_accuracy: 0.69764 |  0:00:55s\n",
      "epoch 87 | loss: 0.82446 | train_accuracy: 0.72106 | valid_accuracy: 0.70659 |  0:00:56s\n",
      "epoch 88 | loss: 0.82334 | train_accuracy: 0.72403 | valid_accuracy: 0.70659 |  0:00:57s\n",
      "epoch 89 | loss: 0.81589 | train_accuracy: 0.72946 | valid_accuracy: 0.70986 |  0:00:57s\n",
      "epoch 90 | loss: 0.81074 | train_accuracy: 0.72725 | valid_accuracy: 0.70812 |  0:00:58s\n",
      "epoch 91 | loss: 0.80739 | train_accuracy: 0.72879 | valid_accuracy: 0.71182 |  0:00:58s\n",
      "epoch 92 | loss: 0.804   | train_accuracy: 0.7272  | valid_accuracy: 0.7127  |  0:00:59s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 | loss: 0.80654 | train_accuracy: 0.72787 | valid_accuracy: 0.71051 |  0:01:00s\n",
      "epoch 94 | loss: 0.7997  | train_accuracy: 0.72942 | valid_accuracy: 0.71095 |  0:01:00s\n",
      "epoch 95 | loss: 0.79913 | train_accuracy: 0.73021 | valid_accuracy: 0.7151  |  0:01:01s\n",
      "epoch 96 | loss: 0.79404 | train_accuracy: 0.72921 | valid_accuracy: 0.71226 |  0:01:02s\n",
      "epoch 97 | loss: 0.79451 | train_accuracy: 0.73343 | valid_accuracy: 0.71466 |  0:01:02s\n",
      "epoch 98 | loss: 0.78839 | train_accuracy: 0.73051 | valid_accuracy: 0.71815 |  0:01:03s\n",
      "epoch 99 | loss: 0.78886 | train_accuracy: 0.73385 | valid_accuracy: 0.71401 |  0:01:03s\n",
      "epoch 100| loss: 0.77867 | train_accuracy: 0.74208 | valid_accuracy: 0.71771 |  0:01:04s\n",
      "epoch 101| loss: 0.76916 | train_accuracy: 0.74145 | valid_accuracy: 0.71619 |  0:01:05s\n",
      "epoch 102| loss: 0.76255 | train_accuracy: 0.74471 | valid_accuracy: 0.71422 |  0:01:05s\n",
      "epoch 103| loss: 0.75267 | train_accuracy: 0.75077 | valid_accuracy: 0.71662 |  0:01:06s\n",
      "epoch 104| loss: 0.74778 | train_accuracy: 0.75182 | valid_accuracy: 0.72251 |  0:01:07s\n",
      "epoch 105| loss: 0.74597 | train_accuracy: 0.75006 | valid_accuracy: 0.72949 |  0:01:07s\n",
      "epoch 106| loss: 0.73798 | train_accuracy: 0.7547  | valid_accuracy: 0.72622 |  0:01:08s\n",
      "epoch 107| loss: 0.7301  | train_accuracy: 0.75453 | valid_accuracy: 0.72535 |  0:01:08s\n",
      "epoch 108| loss: 0.72124 | train_accuracy: 0.76093 | valid_accuracy: 0.73342 |  0:01:09s\n",
      "epoch 109| loss: 0.71516 | train_accuracy: 0.76318 | valid_accuracy: 0.73713 |  0:01:10s\n",
      "epoch 110| loss: 0.7047  | train_accuracy: 0.75951 | valid_accuracy: 0.73037 |  0:01:10s\n",
      "epoch 111| loss: 0.70443 | train_accuracy: 0.76285 | valid_accuracy: 0.73626 |  0:01:11s\n",
      "epoch 112| loss: 0.70552 | train_accuracy: 0.75963 | valid_accuracy: 0.73037 |  0:01:12s\n",
      "epoch 113| loss: 0.71445 | train_accuracy: 0.76126 | valid_accuracy: 0.73757 |  0:01:12s\n",
      "epoch 114| loss: 0.7115  | train_accuracy: 0.76222 | valid_accuracy: 0.73997 |  0:01:13s\n",
      "epoch 115| loss: 0.7073  | train_accuracy: 0.76293 | valid_accuracy: 0.7332  |  0:01:13s\n",
      "epoch 116| loss: 0.70195 | train_accuracy: 0.76281 | valid_accuracy: 0.73822 |  0:01:14s\n",
      "epoch 117| loss: 0.69898 | train_accuracy: 0.76377 | valid_accuracy: 0.73124 |  0:01:15s\n",
      "epoch 118| loss: 0.69283 | train_accuracy: 0.76582 | valid_accuracy: 0.73691 |  0:01:15s\n",
      "epoch 119| loss: 0.68824 | train_accuracy: 0.7672  | valid_accuracy: 0.74455 |  0:01:16s\n",
      "epoch 120| loss: 0.68104 | train_accuracy: 0.76812 | valid_accuracy: 0.74564 |  0:01:17s\n",
      "epoch 121| loss: 0.67735 | train_accuracy: 0.76975 | valid_accuracy: 0.73909 |  0:01:17s\n",
      "epoch 122| loss: 0.66904 | train_accuracy: 0.7733  | valid_accuracy: 0.74935 |  0:01:18s\n",
      "epoch 123| loss: 0.6633  | train_accuracy: 0.77493 | valid_accuracy: 0.74586 |  0:01:18s\n",
      "epoch 124| loss: 0.66093 | train_accuracy: 0.77831 | valid_accuracy: 0.75131 |  0:01:19s\n",
      "epoch 125| loss: 0.65251 | train_accuracy: 0.78057 | valid_accuracy: 0.75    |  0:01:20s\n",
      "epoch 126| loss: 0.65067 | train_accuracy: 0.78149 | valid_accuracy: 0.75458 |  0:01:20s\n",
      "epoch 127| loss: 0.6473  | train_accuracy: 0.78349 | valid_accuracy: 0.75022 |  0:01:21s\n",
      "epoch 128| loss: 0.64271 | train_accuracy: 0.78579 | valid_accuracy: 0.75087 |  0:01:22s\n",
      "epoch 129| loss: 0.63721 | train_accuracy: 0.7865  | valid_accuracy: 0.75349 |  0:01:22s\n",
      "epoch 130| loss: 0.63281 | train_accuracy: 0.78558 | valid_accuracy: 0.75196 |  0:01:23s\n",
      "epoch 131| loss: 0.63594 | train_accuracy: 0.7873  | valid_accuracy: 0.74869 |  0:01:23s\n",
      "epoch 132| loss: 0.63099 | train_accuracy: 0.79051 | valid_accuracy: 0.75196 |  0:01:24s\n",
      "epoch 133| loss: 0.62869 | train_accuracy: 0.7931  | valid_accuracy: 0.75305 |  0:01:25s\n",
      "epoch 134| loss: 0.62263 | train_accuracy: 0.79457 | valid_accuracy: 0.75873 |  0:01:25s\n",
      "epoch 135| loss: 0.6186  | train_accuracy: 0.79628 | valid_accuracy: 0.76243 |  0:01:26s\n",
      "epoch 136| loss: 0.61869 | train_accuracy: 0.79657 | valid_accuracy: 0.76003 |  0:01:27s\n",
      "epoch 137| loss: 0.61335 | train_accuracy: 0.79795 | valid_accuracy: 0.76636 |  0:01:27s\n",
      "epoch 138| loss: 0.6082  | train_accuracy: 0.80393 | valid_accuracy: 0.76723 |  0:01:28s\n",
      "epoch 139| loss: 0.60055 | train_accuracy: 0.80426 | valid_accuracy: 0.76592 |  0:01:29s\n",
      "epoch 140| loss: 0.59422 | train_accuracy: 0.80752 | valid_accuracy: 0.76832 |  0:01:29s\n",
      "epoch 141| loss: 0.58659 | train_accuracy: 0.81103 | valid_accuracy: 0.77007 |  0:01:30s\n",
      "epoch 142| loss: 0.57813 | train_accuracy: 0.81249 | valid_accuracy: 0.7716  |  0:01:30s\n",
      "epoch 143| loss: 0.57003 | train_accuracy: 0.81651 | valid_accuracy: 0.77749 |  0:01:31s\n",
      "epoch 144| loss: 0.56723 | train_accuracy: 0.81596 | valid_accuracy: 0.77312 |  0:01:32s\n",
      "epoch 145| loss: 0.56507 | train_accuracy: 0.81897 | valid_accuracy: 0.77443 |  0:01:32s\n",
      "epoch 146| loss: 0.55832 | train_accuracy: 0.82002 | valid_accuracy: 0.77836 |  0:01:33s\n",
      "epoch 147| loss: 0.55476 | train_accuracy: 0.82181 | valid_accuracy: 0.77661 |  0:01:34s\n",
      "epoch 148| loss: 0.54699 | train_accuracy: 0.82741 | valid_accuracy: 0.77487 |  0:01:34s\n",
      "epoch 149| loss: 0.54341 | train_accuracy: 0.82662 | valid_accuracy: 0.77901 |  0:01:35s\n",
      "epoch 150| loss: 0.53713 | train_accuracy: 0.82921 | valid_accuracy: 0.77552 |  0:01:35s\n",
      "epoch 151| loss: 0.53041 | train_accuracy: 0.83076 | valid_accuracy: 0.78294 |  0:01:36s\n",
      "epoch 152| loss: 0.52737 | train_accuracy: 0.83268 | valid_accuracy: 0.78447 |  0:01:37s\n",
      "epoch 153| loss: 0.52548 | train_accuracy: 0.83339 | valid_accuracy: 0.78098 |  0:01:37s\n",
      "epoch 154| loss: 0.5156  | train_accuracy: 0.83397 | valid_accuracy: 0.7812  |  0:01:38s\n",
      "epoch 155| loss: 0.51493 | train_accuracy: 0.83598 | valid_accuracy: 0.78316 |  0:01:38s\n",
      "epoch 156| loss: 0.5089  | train_accuracy: 0.83861 | valid_accuracy: 0.78752 |  0:01:39s\n",
      "epoch 157| loss: 0.51068 | train_accuracy: 0.84003 | valid_accuracy: 0.78949 |  0:01:40s\n",
      "epoch 158| loss: 0.50179 | train_accuracy: 0.84133 | valid_accuracy: 0.79101 |  0:01:40s\n",
      "epoch 159| loss: 0.49812 | train_accuracy: 0.84099 | valid_accuracy: 0.79254 |  0:01:41s\n",
      "epoch 160| loss: 0.49478 | train_accuracy: 0.84421 | valid_accuracy: 0.79538 |  0:01:42s\n",
      "epoch 161| loss: 0.49006 | train_accuracy: 0.84538 | valid_accuracy: 0.79777 |  0:01:42s\n",
      "epoch 162| loss: 0.48511 | train_accuracy: 0.84735 | valid_accuracy: 0.79538 |  0:01:43s\n",
      "epoch 163| loss: 0.47839 | train_accuracy: 0.84781 | valid_accuracy: 0.79494 |  0:01:44s\n",
      "epoch 164| loss: 0.47629 | train_accuracy: 0.85144 | valid_accuracy: 0.79647 |  0:01:44s\n",
      "epoch 165| loss: 0.47001 | train_accuracy: 0.85069 | valid_accuracy: 0.79516 |  0:01:45s\n",
      "epoch 166| loss: 0.46829 | train_accuracy: 0.85215 | valid_accuracy: 0.79843 |  0:01:45s\n",
      "epoch 167| loss: 0.4637  | train_accuracy: 0.85533 | valid_accuracy: 0.79777 |  0:01:46s\n",
      "epoch 168| loss: 0.46366 | train_accuracy: 0.85349 | valid_accuracy: 0.79625 |  0:01:47s\n",
      "epoch 169| loss: 0.45819 | train_accuracy: 0.85629 | valid_accuracy: 0.79865 |  0:01:47s\n",
      "epoch 170| loss: 0.45843 | train_accuracy: 0.85566 | valid_accuracy: 0.80127 |  0:01:48s\n",
      "epoch 171| loss: 0.45809 | train_accuracy: 0.85516 | valid_accuracy: 0.80192 |  0:01:49s\n",
      "epoch 172| loss: 0.45616 | train_accuracy: 0.85537 | valid_accuracy: 0.80301 |  0:01:49s\n",
      "epoch 173| loss: 0.45822 | train_accuracy: 0.8565  | valid_accuracy: 0.8017  |  0:01:50s\n",
      "epoch 174| loss: 0.45642 | train_accuracy: 0.85717 | valid_accuracy: 0.80585 |  0:01:51s\n",
      "epoch 175| loss: 0.45403 | train_accuracy: 0.85746 | valid_accuracy: 0.80432 |  0:01:51s\n",
      "epoch 176| loss: 0.45057 | train_accuracy: 0.86022 | valid_accuracy: 0.80585 |  0:01:52s\n",
      "epoch 177| loss: 0.44927 | train_accuracy: 0.85951 | valid_accuracy: 0.81152 |  0:01:53s\n",
      "epoch 178| loss: 0.44182 | train_accuracy: 0.86185 | valid_accuracy: 0.80606 |  0:01:53s\n",
      "epoch 179| loss: 0.44015 | train_accuracy: 0.86226 | valid_accuracy: 0.80497 |  0:01:54s\n",
      "epoch 180| loss: 0.43377 | train_accuracy: 0.86435 | valid_accuracy: 0.81348 |  0:01:55s\n",
      "epoch 181| loss: 0.42971 | train_accuracy: 0.86498 | valid_accuracy: 0.80803 |  0:01:55s\n",
      "epoch 182| loss: 0.42455 | train_accuracy: 0.86561 | valid_accuracy: 0.8089  |  0:01:56s\n",
      "epoch 183| loss: 0.42381 | train_accuracy: 0.8672  | valid_accuracy: 0.80694 |  0:01:56s\n",
      "epoch 184| loss: 0.4222  | train_accuracy: 0.86849 | valid_accuracy: 0.80825 |  0:01:57s\n",
      "epoch 185| loss: 0.41794 | train_accuracy: 0.86883 | valid_accuracy: 0.80541 |  0:01:58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 186| loss: 0.41449 | train_accuracy: 0.87004 | valid_accuracy: 0.80388 |  0:01:58s\n",
      "epoch 187| loss: 0.41288 | train_accuracy: 0.87296 | valid_accuracy: 0.81174 |  0:01:59s\n",
      "epoch 188| loss: 0.40965 | train_accuracy: 0.87234 | valid_accuracy: 0.81305 |  0:02:00s\n",
      "epoch 189| loss: 0.40735 | train_accuracy: 0.87472 | valid_accuracy: 0.81021 |  0:02:00s\n",
      "epoch 190| loss: 0.40415 | train_accuracy: 0.87593 | valid_accuracy: 0.81195 |  0:02:01s\n",
      "epoch 191| loss: 0.40288 | train_accuracy: 0.87522 | valid_accuracy: 0.81479 |  0:02:01s\n",
      "epoch 192| loss: 0.39731 | train_accuracy: 0.87664 | valid_accuracy: 0.81501 |  0:02:02s\n",
      "epoch 193| loss: 0.39496 | train_accuracy: 0.87777 | valid_accuracy: 0.81741 |  0:02:03s\n",
      "epoch 194| loss: 0.39314 | train_accuracy: 0.88023 | valid_accuracy: 0.81763 |  0:02:03s\n",
      "epoch 195| loss: 0.38888 | train_accuracy: 0.87798 | valid_accuracy: 0.81501 |  0:02:04s\n",
      "epoch 196| loss: 0.38316 | train_accuracy: 0.88186 | valid_accuracy: 0.82155 |  0:02:05s\n",
      "epoch 197| loss: 0.38728 | train_accuracy: 0.88161 | valid_accuracy: 0.82177 |  0:02:05s\n",
      "epoch 198| loss: 0.3792  | train_accuracy: 0.88132 | valid_accuracy: 0.82177 |  0:02:06s\n",
      "epoch 199| loss: 0.37486 | train_accuracy: 0.88399 | valid_accuracy: 0.82068 |  0:02:07s\n",
      "epoch 200| loss: 0.37266 | train_accuracy: 0.88575 | valid_accuracy: 0.82483 |  0:02:07s\n",
      "epoch 201| loss: 0.36745 | train_accuracy: 0.88546 | valid_accuracy: 0.82264 |  0:02:08s\n",
      "epoch 202| loss: 0.36966 | train_accuracy: 0.88654 | valid_accuracy: 0.82199 |  0:02:09s\n",
      "epoch 203| loss: 0.36785 | train_accuracy: 0.88546 | valid_accuracy: 0.82134 |  0:02:09s\n",
      "epoch 204| loss: 0.36608 | train_accuracy: 0.88483 | valid_accuracy: 0.81937 |  0:02:10s\n",
      "epoch 205| loss: 0.36859 | train_accuracy: 0.88257 | valid_accuracy: 0.8185  |  0:02:11s\n",
      "epoch 206| loss: 0.36629 | train_accuracy: 0.8845  | valid_accuracy: 0.81763 |  0:02:11s\n",
      "epoch 207| loss: 0.36992 | train_accuracy: 0.88387 | valid_accuracy: 0.82199 |  0:02:12s\n",
      "epoch 208| loss: 0.38231 | train_accuracy: 0.88011 | valid_accuracy: 0.81915 |  0:02:12s\n",
      "epoch 209| loss: 0.38905 | train_accuracy: 0.8809  | valid_accuracy: 0.82134 |  0:02:13s\n",
      "epoch 210| loss: 0.38866 | train_accuracy: 0.8789  | valid_accuracy: 0.82243 |  0:02:14s\n",
      "epoch 211| loss: 0.38481 | train_accuracy: 0.88228 | valid_accuracy: 0.81981 |  0:02:14s\n",
      "epoch 212| loss: 0.38063 | train_accuracy: 0.88282 | valid_accuracy: 0.82243 |  0:02:15s\n",
      "epoch 213| loss: 0.37494 | train_accuracy: 0.88454 | valid_accuracy: 0.82134 |  0:02:16s\n",
      "epoch 214| loss: 0.36792 | train_accuracy: 0.88429 | valid_accuracy: 0.82243 |  0:02:16s\n",
      "epoch 215| loss: 0.36477 | train_accuracy: 0.88642 | valid_accuracy: 0.82308 |  0:02:17s\n",
      "epoch 216| loss: 0.3616  | train_accuracy: 0.88813 | valid_accuracy: 0.82395 |  0:02:17s\n",
      "epoch 217| loss: 0.35707 | train_accuracy: 0.88918 | valid_accuracy: 0.82526 |  0:02:18s\n",
      "epoch 218| loss: 0.35224 | train_accuracy: 0.89244 | valid_accuracy: 0.82548 |  0:02:19s\n",
      "epoch 219| loss: 0.35043 | train_accuracy: 0.89193 | valid_accuracy: 0.82679 |  0:02:19s\n",
      "epoch 220| loss: 0.34421 | train_accuracy: 0.89549 | valid_accuracy: 0.82984 |  0:02:20s\n",
      "epoch 221| loss: 0.34282 | train_accuracy: 0.89461 | valid_accuracy: 0.83072 |  0:02:21s\n",
      "epoch 222| loss: 0.33857 | train_accuracy: 0.8972  | valid_accuracy: 0.83224 |  0:02:21s\n",
      "epoch 223| loss: 0.33597 | train_accuracy: 0.89783 | valid_accuracy: 0.82592 |  0:02:22s\n",
      "epoch 224| loss: 0.33406 | train_accuracy: 0.89858 | valid_accuracy: 0.82788 |  0:02:22s\n",
      "epoch 225| loss: 0.33031 | train_accuracy: 0.89728 | valid_accuracy: 0.83072 |  0:02:23s\n",
      "epoch 226| loss: 0.32851 | train_accuracy: 0.89678 | valid_accuracy: 0.82984 |  0:02:24s\n",
      "epoch 227| loss: 0.33412 | train_accuracy: 0.89695 | valid_accuracy: 0.82962 |  0:02:24s\n",
      "epoch 228| loss: 0.3358  | train_accuracy: 0.89779 | valid_accuracy: 0.83006 |  0:02:25s\n",
      "epoch 229| loss: 0.33529 | train_accuracy: 0.89707 | valid_accuracy: 0.83617 |  0:02:26s\n",
      "epoch 230| loss: 0.33741 | train_accuracy: 0.89143 | valid_accuracy: 0.83159 |  0:02:26s\n",
      "epoch 231| loss: 0.34736 | train_accuracy: 0.88792 | valid_accuracy: 0.82483 |  0:02:27s\n",
      "epoch 232| loss: 0.35712 | train_accuracy: 0.8893  | valid_accuracy: 0.82701 |  0:02:28s\n",
      "epoch 233| loss: 0.35195 | train_accuracy: 0.89239 | valid_accuracy: 0.82962 |  0:02:28s\n",
      "epoch 234| loss: 0.3533  | train_accuracy: 0.89185 | valid_accuracy: 0.83028 |  0:02:29s\n",
      "epoch 235| loss: 0.34551 | train_accuracy: 0.8944  | valid_accuracy: 0.83159 |  0:02:30s\n",
      "epoch 236| loss: 0.33697 | train_accuracy: 0.89649 | valid_accuracy: 0.83268 |  0:02:30s\n",
      "epoch 237| loss: 0.32994 | train_accuracy: 0.89795 | valid_accuracy: 0.83399 |  0:02:31s\n",
      "epoch 238| loss: 0.32779 | train_accuracy: 0.9     | valid_accuracy: 0.83508 |  0:02:31s\n",
      "epoch 239| loss: 0.3219  | train_accuracy: 0.90276 | valid_accuracy: 0.83551 |  0:02:32s\n",
      "epoch 240| loss: 0.31845 | train_accuracy: 0.90205 | valid_accuracy: 0.82984 |  0:02:33s\n",
      "epoch 241| loss: 0.31337 | train_accuracy: 0.90598 | valid_accuracy: 0.8377  |  0:02:33s\n",
      "epoch 242| loss: 0.31419 | train_accuracy: 0.90694 | valid_accuracy: 0.83661 |  0:02:34s\n",
      "epoch 243| loss: 0.30764 | train_accuracy: 0.90798 | valid_accuracy: 0.83857 |  0:02:35s\n",
      "epoch 244| loss: 0.3063  | train_accuracy: 0.90832 | valid_accuracy: 0.83791 |  0:02:35s\n",
      "epoch 245| loss: 0.30001 | train_accuracy: 0.91178 | valid_accuracy: 0.83988 |  0:02:36s\n",
      "epoch 246| loss: 0.29661 | train_accuracy: 0.91124 | valid_accuracy: 0.84097 |  0:02:37s\n",
      "epoch 247| loss: 0.2945  | train_accuracy: 0.91249 | valid_accuracy: 0.83813 |  0:02:37s\n",
      "epoch 248| loss: 0.29217 | train_accuracy: 0.91321 | valid_accuracy: 0.84031 |  0:02:38s\n",
      "epoch 249| loss: 0.29067 | train_accuracy: 0.9145  | valid_accuracy: 0.84184 |  0:02:38s\n",
      "epoch 250| loss: 0.28522 | train_accuracy: 0.91513 | valid_accuracy: 0.84293 |  0:02:39s\n",
      "epoch 251| loss: 0.28591 | train_accuracy: 0.915   | valid_accuracy: 0.84359 |  0:02:40s\n",
      "epoch 252| loss: 0.2849  | train_accuracy: 0.91509 | valid_accuracy: 0.84293 |  0:02:40s\n",
      "epoch 253| loss: 0.28752 | train_accuracy: 0.91609 | valid_accuracy: 0.84228 |  0:02:41s\n",
      "epoch 254| loss: 0.28541 | train_accuracy: 0.91442 | valid_accuracy: 0.84577 |  0:02:42s\n",
      "epoch 255| loss: 0.28327 | train_accuracy: 0.91734 | valid_accuracy: 0.8462  |  0:02:42s\n",
      "epoch 256| loss: 0.27887 | train_accuracy: 0.91864 | valid_accuracy: 0.84839 |  0:02:43s\n",
      "epoch 257| loss: 0.27976 | train_accuracy: 0.91784 | valid_accuracy: 0.84664 |  0:02:44s\n",
      "epoch 258| loss: 0.27392 | train_accuracy: 0.91751 | valid_accuracy: 0.84424 |  0:02:44s\n",
      "epoch 259| loss: 0.27965 | train_accuracy: 0.91521 | valid_accuracy: 0.8438  |  0:02:45s\n",
      "epoch 260| loss: 0.27746 | train_accuracy: 0.91701 | valid_accuracy: 0.84533 |  0:02:45s\n",
      "epoch 261| loss: 0.27601 | train_accuracy: 0.91713 | valid_accuracy: 0.84119 |  0:02:46s\n",
      "epoch 262| loss: 0.27503 | train_accuracy: 0.9196  | valid_accuracy: 0.84468 |  0:02:47s\n",
      "epoch 263| loss: 0.27344 | train_accuracy: 0.91822 | valid_accuracy: 0.84337 |  0:02:47s\n",
      "epoch 264| loss: 0.27569 | train_accuracy: 0.91743 | valid_accuracy: 0.84402 |  0:02:48s\n",
      "epoch 265| loss: 0.27659 | train_accuracy: 0.91726 | valid_accuracy: 0.84402 |  0:02:49s\n",
      "epoch 266| loss: 0.27358 | train_accuracy: 0.91446 | valid_accuracy: 0.84315 |  0:02:49s\n",
      "epoch 267| loss: 0.28057 | train_accuracy: 0.91199 | valid_accuracy: 0.84337 |  0:02:50s\n",
      "epoch 268| loss: 0.28911 | train_accuracy: 0.91187 | valid_accuracy: 0.84228 |  0:02:50s\n",
      "epoch 269| loss: 0.29365 | train_accuracy: 0.91183 | valid_accuracy: 0.84053 |  0:02:51s\n",
      "epoch 270| loss: 0.2858  | train_accuracy: 0.9122  | valid_accuracy: 0.84359 |  0:02:52s\n",
      "epoch 271| loss: 0.28576 | train_accuracy: 0.9158  | valid_accuracy: 0.84533 |  0:02:52s\n",
      "epoch 272| loss: 0.28027 | train_accuracy: 0.91676 | valid_accuracy: 0.84293 |  0:02:53s\n",
      "epoch 273| loss: 0.27327 | train_accuracy: 0.91897 | valid_accuracy: 0.85057 |  0:02:54s\n",
      "epoch 274| loss: 0.27116 | train_accuracy: 0.91972 | valid_accuracy: 0.84359 |  0:02:54s\n",
      "epoch 275| loss: 0.26776 | train_accuracy: 0.92073 | valid_accuracy: 0.84555 |  0:02:55s\n",
      "epoch 276| loss: 0.2661  | train_accuracy: 0.92052 | valid_accuracy: 0.84359 |  0:02:56s\n",
      "epoch 277| loss: 0.26606 | train_accuracy: 0.9214  | valid_accuracy: 0.84097 |  0:02:56s\n",
      "epoch 278| loss: 0.26165 | train_accuracy: 0.92307 | valid_accuracy: 0.84686 |  0:02:57s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 279| loss: 0.26042 | train_accuracy: 0.92353 | valid_accuracy: 0.84533 |  0:02:57s\n",
      "epoch 280| loss: 0.2582  | train_accuracy: 0.92599 | valid_accuracy: 0.84948 |  0:02:58s\n",
      "epoch 281| loss: 0.25337 | train_accuracy: 0.92595 | valid_accuracy: 0.8449  |  0:02:59s\n",
      "epoch 282| loss: 0.25347 | train_accuracy: 0.92624 | valid_accuracy: 0.84817 |  0:02:59s\n",
      "epoch 283| loss: 0.25122 | train_accuracy: 0.92674 | valid_accuracy: 0.84577 |  0:03:00s\n",
      "epoch 284| loss: 0.25414 | train_accuracy: 0.92612 | valid_accuracy: 0.84555 |  0:03:01s\n",
      "epoch 285| loss: 0.24995 | train_accuracy: 0.92503 | valid_accuracy: 0.84293 |  0:03:01s\n",
      "epoch 286| loss: 0.24982 | train_accuracy: 0.92679 | valid_accuracy: 0.84446 |  0:03:02s\n",
      "epoch 287| loss: 0.24953 | train_accuracy: 0.92708 | valid_accuracy: 0.84271 |  0:03:03s\n",
      "epoch 288| loss: 0.24949 | train_accuracy: 0.92741 | valid_accuracy: 0.84708 |  0:03:03s\n",
      "epoch 289| loss: 0.25345 | train_accuracy: 0.92695 | valid_accuracy: 0.84795 |  0:03:04s\n",
      "epoch 290| loss: 0.24602 | train_accuracy: 0.92833 | valid_accuracy: 0.84969 |  0:03:05s\n",
      "epoch 291| loss: 0.24842 | train_accuracy: 0.92491 | valid_accuracy: 0.84969 |  0:03:05s\n",
      "epoch 292| loss: 0.24884 | train_accuracy: 0.9244  | valid_accuracy: 0.84948 |  0:03:06s\n",
      "epoch 293| loss: 0.25548 | train_accuracy: 0.92286 | valid_accuracy: 0.84969 |  0:03:06s\n",
      "epoch 294| loss: 0.26207 | train_accuracy: 0.92344 | valid_accuracy: 0.84969 |  0:03:07s\n",
      "epoch 295| loss: 0.26242 | train_accuracy: 0.92277 | valid_accuracy: 0.84991 |  0:03:08s\n",
      "epoch 296| loss: 0.2589  | train_accuracy: 0.92014 | valid_accuracy: 0.84293 |  0:03:08s\n",
      "epoch 297| loss: 0.26647 | train_accuracy: 0.92181 | valid_accuracy: 0.84315 |  0:03:09s\n",
      "epoch 298| loss: 0.26676 | train_accuracy: 0.91943 | valid_accuracy: 0.84271 |  0:03:10s\n",
      "epoch 299| loss: 0.26937 | train_accuracy: 0.92357 | valid_accuracy: 0.84817 |  0:03:10s\n",
      "Stop training because you reached max_epochs = 300 with best_epoch = 273 and best_valid_accuracy = 0.85057\n",
      "Best weights from best epoch are automatically used!\n"
     ]
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_test, y_test)], #(X_validx, y_validx)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    max_epochs=300, patience=100,\n",
    "    batch_size=16384, virtual_batch_size=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21e42aa370>]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "plt.plot(clf.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f21e40cbc10>]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "plt.plot(clf.history['train_accuracy'])\n",
    "plt.plot(clf.history['valid_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = np.argmax(preds, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_dict = {0:1, 1:2, 2:3, 3:5, 4:6, 5:8, 6:10, 7:11, 8:12, 9:13, 10:15, 11:16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_with_dict(ar, dic):\n",
    "    # Extract out keys and values\n",
    "    k = np.array(list(dic.keys()))\n",
    "    v = np.array(list(dic.values()))\n",
    "\n",
    "    # Get argsort indices\n",
    "    sidx = k.argsort()\n",
    "\n",
    "    # Drop the magic bomb with searchsorted to get the corresponding\n",
    "    # places for a in keys (using sorter since a is not necessarily sorted).\n",
    "    # Then trace it back to original order with indexing into sidx\n",
    "    # Finally index into values for desired output.\n",
    "    return v[sidx[np.searchsorted(k,ar,sorter=sidx)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = replace_with_dict(y_preds, crop_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST VALID SCORE FOR : 0.9481821980777267\n",
      "FINAL TEST SCORE FOR : 0.9081588132635253\n"
     ]
    }
   ],
   "source": [
    "test_acc = accuracy_score(y_pred=y_preds, y_true=y_test)\n",
    "\n",
    "print(f\"BEST VALID SCORE FOR : {clf.best_cost}\")\n",
    "print(f\"FINAL TEST SCORE FOR : {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>B02_0322</th>\n",
       "      <th>B03_0322</th>\n",
       "      <th>B04_0322</th>\n",
       "      <th>B05_0322</th>\n",
       "      <th>B06_0322</th>\n",
       "      <th>B07_0322</th>\n",
       "      <th>B08A_0322</th>\n",
       "      <th>B08_0322</th>\n",
       "      <th>B11_0322</th>\n",
       "      <th>...</th>\n",
       "      <th>VH_20180905</th>\n",
       "      <th>VV_20180905</th>\n",
       "      <th>VH_20180913</th>\n",
       "      <th>VV_20180913</th>\n",
       "      <th>VH_20180917</th>\n",
       "      <th>VV_20180917</th>\n",
       "      <th>VH_20180925</th>\n",
       "      <th>VV_20180925</th>\n",
       "      <th>VH_20180929</th>\n",
       "      <th>VV_20180929</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crop_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geometry  B02_0322  B03_0322  B04_0322  B05_0322  B06_0322  B07_0322  \\\n",
       "crop_id                                                                         \n",
       "1             100       100       100       100       100       100       100   \n",
       "2             100       100       100       100       100       100       100   \n",
       "3             100       100       100       100       100       100       100   \n",
       "5             100       100       100       100       100       100       100   \n",
       "6             100       100       100       100       100       100       100   \n",
       "8             100       100       100       100       100       100       100   \n",
       "10            100       100       100       100       100       100       100   \n",
       "11            100       100       100       100       100       100       100   \n",
       "12            100       100       100       100       100       100       100   \n",
       "13            100       100       100       100       100       100       100   \n",
       "15            100       100       100       100       100       100       100   \n",
       "16            100       100       100       100       100       100       100   \n",
       "\n",
       "         B08A_0322  B08_0322  B11_0322  ...  VH_20180905  VV_20180905  \\\n",
       "crop_id                                 ...                             \n",
       "1              100       100       100  ...          100          100   \n",
       "2              100       100       100  ...          100          100   \n",
       "3              100       100       100  ...          100          100   \n",
       "5              100       100       100  ...          100          100   \n",
       "6              100       100       100  ...          100          100   \n",
       "8              100       100       100  ...          100          100   \n",
       "10             100       100       100  ...          100          100   \n",
       "11             100       100       100  ...          100          100   \n",
       "12             100       100       100  ...          100          100   \n",
       "13             100       100       100  ...          100          100   \n",
       "15             100       100       100  ...          100          100   \n",
       "16             100       100       100  ...          100          100   \n",
       "\n",
       "         VH_20180913  VV_20180913  VH_20180917  VV_20180917  VH_20180925  \\\n",
       "crop_id                                                                    \n",
       "1                100          100          100          100          100   \n",
       "2                100          100          100          100          100   \n",
       "3                100          100          100          100          100   \n",
       "5                100          100          100          100          100   \n",
       "6                100          100          100          100          100   \n",
       "8                100          100          100          100          100   \n",
       "10               100          100          100          100          100   \n",
       "11               100          100          100          100          100   \n",
       "12               100          100          100          100          100   \n",
       "13               100          100          100          100          100   \n",
       "15               100          100          100          100          100   \n",
       "16               100          100          100          100          100   \n",
       "\n",
       "         VV_20180925  VH_20180929  VV_20180929  \n",
       "crop_id                                         \n",
       "1                100          100          100  \n",
       "2                100          100          100  \n",
       "3                100          100          100  \n",
       "5                100          100          100  \n",
       "6                100          100          100  \n",
       "8                100          100          100  \n",
       "10               100          100          100  \n",
       "11               100          100          100  \n",
       "12               100          100          100  \n",
       "13               100          100          100  \n",
       "15               100          100          100  \n",
       "16               100          100          100  \n",
       "\n",
       "[12 rows x 240 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.groupby(['crop_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>B02_0322</th>\n",
       "      <th>B03_0322</th>\n",
       "      <th>B04_0322</th>\n",
       "      <th>B05_0322</th>\n",
       "      <th>B06_0322</th>\n",
       "      <th>B07_0322</th>\n",
       "      <th>B08A_0322</th>\n",
       "      <th>B08_0322</th>\n",
       "      <th>B11_0322</th>\n",
       "      <th>...</th>\n",
       "      <th>VH_20180905</th>\n",
       "      <th>VV_20180905</th>\n",
       "      <th>VH_20180913</th>\n",
       "      <th>VV_20180913</th>\n",
       "      <th>VH_20180917</th>\n",
       "      <th>VV_20180917</th>\n",
       "      <th>VH_20180925</th>\n",
       "      <th>VV_20180925</th>\n",
       "      <th>VH_20180929</th>\n",
       "      <th>VV_20180929</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crop_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>...</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>...</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "      <td>380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 240 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         geometry  B02_0322  B03_0322  B04_0322  B05_0322  B06_0322  B07_0322  \\\n",
       "crop_id                                                                         \n",
       "1             400       400       400       400       400       400       400   \n",
       "2             400       400       400       400       400       400       400   \n",
       "3             400       400       400       400       400       400       400   \n",
       "5             400       400       400       400       400       400       400   \n",
       "6             400       400       400       400       400       400       400   \n",
       "8             400       400       400       400       400       400       400   \n",
       "10            400       400       400       400       400       400       400   \n",
       "11            400       400       400       400       400       400       400   \n",
       "12            400       400       400       400       400       400       400   \n",
       "13            400       400       400       400       400       400       400   \n",
       "15            380       380       380       380       380       380       380   \n",
       "16            204       204       204       204       204       204       204   \n",
       "\n",
       "         B08A_0322  B08_0322  B11_0322  ...  VH_20180905  VV_20180905  \\\n",
       "crop_id                                 ...                             \n",
       "1              400       400       400  ...          400          400   \n",
       "2              400       400       400  ...          400          400   \n",
       "3              400       400       400  ...          400          400   \n",
       "5              400       400       400  ...          400          400   \n",
       "6              400       400       400  ...          400          400   \n",
       "8              400       400       400  ...          400          400   \n",
       "10             400       400       400  ...          400          400   \n",
       "11             400       400       400  ...          400          400   \n",
       "12             400       400       400  ...          400          400   \n",
       "13             400       400       400  ...          400          400   \n",
       "15             380       380       380  ...          380          380   \n",
       "16             204       204       204  ...          204          204   \n",
       "\n",
       "         VH_20180913  VV_20180913  VH_20180917  VV_20180917  VH_20180925  \\\n",
       "crop_id                                                                    \n",
       "1                400          400          400          400          400   \n",
       "2                400          400          400          400          400   \n",
       "3                400          400          400          400          400   \n",
       "5                400          400          400          400          400   \n",
       "6                400          400          400          400          400   \n",
       "8                400          400          400          400          400   \n",
       "10               400          400          400          400          400   \n",
       "11               400          400          400          400          400   \n",
       "12               400          400          400          400          400   \n",
       "13               400          400          400          400          400   \n",
       "15               380          380          380          380          380   \n",
       "16               204          204          204          204          204   \n",
       "\n",
       "         VV_20180925  VH_20180929  VV_20180929  \n",
       "crop_id                                         \n",
       "1                400          400          400  \n",
       "2                400          400          400  \n",
       "3                400          400          400  \n",
       "5                400          400          400  \n",
       "6                400          400          400  \n",
       "8                400          400          400  \n",
       "10               400          400          400  \n",
       "11               400          400          400  \n",
       "12               400          400          400  \n",
       "13               400          400          400  \n",
       "15               380          380          380  \n",
       "16               204          204          204  \n",
       "\n",
       "[12 rows x 240 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.groupby(['crop_id']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5784"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1200+4584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004184100418410041"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1/(X_train.shape[1]*X_train.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "239"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "kaggle"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
